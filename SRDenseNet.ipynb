{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"BTP - SRDenseNet.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyOapfYyVQlTWBdI1fU/1G1h"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"K4Ei0p-l8mIA","executionInfo":{"status":"ok","timestamp":1619852413265,"user_tz":-330,"elapsed":1148,"user":{"displayName":"ASHISH KUMAR 4-Yr B.Tech. Comp. Sci. and Engg, 2018-2022","photoUrl":"","userId":"09157645467553063630"}},"outputId":"317df208-9c06-4ce6-9681-89d4c0d982ec"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":8,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"zQZt4x2o89zm","executionInfo":{"status":"ok","timestamp":1619852415395,"user_tz":-330,"elapsed":1212,"user":{"displayName":"ASHISH KUMAR 4-Yr B.Tech. Comp. Sci. and Engg, 2018-2022","photoUrl":"","userId":"09157645467553063630"}}},"source":["import random\n","import h5py\n","import numpy as np\n","from torch.utils.data import Dataset\n","\n","\n","class TrainDataset(Dataset):\n","    def __init__(self, h5_file, patch_size, scale):\n","        super(TrainDataset, self).__init__()\n","        self.h5_file = h5_file\n","        self.patch_size = patch_size // scale\n","        self.scale = scale\n","\n","    def random_crop(self, lr, hr):\n","        x = random.randint(0, lr.shape[-1] - self.patch_size)\n","        y = random.randint(0, lr.shape[-2] - self.patch_size)\n","        lr = lr[:, y:y+self.patch_size, x:x+self.patch_size]\n","        hr = hr[:, y*self.scale:y*self.scale+self.patch_size*self.scale, x*self.scale:x*self.scale+self.patch_size*self.scale]\n","        return lr, hr\n","\n","    def __getitem__(self, idx):\n","        with h5py.File(self.h5_file, 'r') as f:\n","            lr = np.expand_dims(f['lr'][str(idx)][::].astype(np.float32), 0) / 255.0\n","            hr = np.expand_dims(f['hr'][str(idx)][::].astype(np.float32), 0) / 255.0\n","            lr, hr = self.random_crop(lr, hr)\n","            return lr, hr\n","\n","    def __len__(self):\n","        with h5py.File(self.h5_file, 'r') as f:\n","            return len(f['lr'])\n","\n","\n","class EvalDataset(Dataset):\n","    def __init__(self, h5_file):\n","        super(EvalDataset, self).__init__()\n","        self.h5_file = h5_file\n","\n","    def __getitem__(self, idx):\n","        with h5py.File(self.h5_file, 'r') as f:\n","            lr = np.expand_dims(f['lr'][str(idx)][::].astype(np.float32), 0) / 255.0\n","            hr = np.expand_dims(f['hr'][str(idx)][::].astype(np.float32), 0) / 255.0\n","            return lr, hr\n","\n","    def __len__(self):\n","        with h5py.File(self.h5_file, 'r') as f:\n","            return len(f['lr'])"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"id":"nq5D4Z4m9BJT","executionInfo":{"status":"ok","timestamp":1619852418043,"user_tz":-330,"elapsed":1708,"user":{"displayName":"ASHISH KUMAR 4-Yr B.Tech. Comp. Sci. and Engg, 2018-2022","photoUrl":"","userId":"09157645467553063630"}}},"source":["import torch\n","from torch import nn\n","\n","\n","class ConvLayer(nn.Module):\n","    def __init__(self, in_channels, out_channels, kernel_size):\n","        super(ConvLayer, self).__init__()\n","        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=kernel_size, padding=kernel_size // 2)\n","        self.relu = nn.ReLU(inplace=True)\n","\n","    def forward(self, x):\n","        return self.relu(self.conv(x))\n","\n","\n","class DenseLayer(nn.Module):\n","    def __init__(self, in_channels, out_channels, kernel_size):\n","        super(DenseLayer, self).__init__()\n","        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=kernel_size, padding=kernel_size // 2)\n","        self.relu = nn.ReLU(inplace=True)\n","\n","    def forward(self, x):\n","        return torch.cat([x, self.relu(self.conv(x))], 1)\n","\n","\n","class DenseBlock(nn.Module):\n","    def __init__(self, in_channels, growth_rate, num_layers):\n","        super(DenseBlock, self).__init__()\n","        self.block = [ConvLayer(in_channels, growth_rate, kernel_size=3)]\n","        for i in range(num_layers - 1):\n","            self.block.append(DenseLayer(growth_rate * (i + 1), growth_rate, kernel_size=3))\n","        self.block = nn.Sequential(*self.block)\n","\n","    def forward(self, x):\n","        return torch.cat([x, self.block(x)], 1)\n","\n","\n","class SRDenseNet(nn.Module):\n","    def __init__(self, num_channels=1, growth_rate=16, num_blocks=8, num_layers=8):\n","        super(SRDenseNet, self).__init__()\n","\n","        # low level features\n","        self.conv = ConvLayer(num_channels, growth_rate * num_layers, 3)\n","\n","        # high level features\n","        self.dense_blocks = []\n","        for i in range(num_blocks):\n","            self.dense_blocks.append(DenseBlock(growth_rate * num_layers * (i + 1), growth_rate, num_layers))\n","        self.dense_blocks = nn.Sequential(*self.dense_blocks)\n","\n","        # bottleneck layer\n","        self.bottleneck = nn.Sequential(\n","            nn.Conv2d(growth_rate * num_layers + growth_rate * num_layers * num_blocks, 256, kernel_size=1),\n","            nn.ReLU(inplace=True)\n","        )\n","\n","        # deconvolution layers\n","        self.deconv = nn.Sequential(\n","            nn.ConvTranspose2d(256, 256, kernel_size=3, stride=2, padding=3 // 2, output_padding=1),\n","            nn.ReLU(inplace=True),\n","            nn.ConvTranspose2d(256, 256, kernel_size=3, stride=2, padding=3 // 2, output_padding=1),\n","            nn.ReLU(inplace=True)\n","        )\n","\n","        # reconstruction layer\n","        self.reconstruction = nn.Conv2d(256, num_channels, kernel_size=3, padding=3 // 2)\n","\n","        self._initialize_weights()\n","\n","    def _initialize_weights(self):\n","        for m in self.modules():\n","            if isinstance(m, nn.Conv2d) or isinstance(m, nn.ConvTranspose2d):\n","                nn.init.kaiming_normal_(m.weight.data, nonlinearity='relu')\n","                if m.bias is not None:\n","                    nn.init.zeros_(m.bias.data)\n","\n","    def forward(self, x):\n","        x = self.conv(x)\n","        x = self.dense_blocks(x)\n","        x = self.bottleneck(x)\n","        x = self.deconv(x)\n","        x = self.reconstruction(x)\n","        return x"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"id":"vea_10y19D2b","executionInfo":{"status":"ok","timestamp":1619852618196,"user_tz":-330,"elapsed":1020,"user":{"displayName":"ASHISH KUMAR 4-Yr B.Tech. Comp. Sci. and Engg, 2018-2022","photoUrl":"","userId":"09157645467553063630"}}},"source":["import torch\n","import numpy as np\n","from scipy.ndimage import gaussian_filter\n","\n","\n","def calc_patch_size(func):\n","    def wrapper(args):\n","        if scale == 2:\n","            patch_size = 10\n","        elif scale == 3:\n","            patch_size = 7\n","        elif scale == 4:\n","            patch_size = 6\n","        else:\n","            raise Exception('Scale Error', scale)\n","        return func(args)\n","    return wrapper\n","\n","\n","def convert_rgb_to_y(img, dim_order='hwc'):\n","    if dim_order == 'hwc':\n","        return 16. + (64.738 * img[..., 0] + 129.057 * img[..., 1] + 25.064 * img[..., 2]) / 256.\n","    else:\n","        return 16. + (64.738 * img[0] + 129.057 * img[1] + 25.064 * img[2]) / 256.\n","\n","\n","def convert_rgb_to_ycbcr(img, dim_order='hwc'):\n","    if dim_order == 'hwc':\n","        y = 16. + (64.738 * img[..., 0] + 129.057 * img[..., 1] + 25.064 * img[..., 2]) / 256.\n","        cb = 128. + (-37.945 * img[..., 0] - 74.494 * img[..., 1] + 112.439 * img[..., 2]) / 256.\n","        cr = 128. + (112.439 * img[..., 0] - 94.154 * img[..., 1] - 18.285 * img[..., 2]) / 256.\n","    else:\n","        y = 16. + (64.738 * img[0] + 129.057 * img[1] + 25.064 * img[2]) / 256.\n","        cb = 128. + (-37.945 * img[0] - 74.494 * img[1] + 112.439 * img[2]) / 256.\n","        cr = 128. + (112.439 * img[0] - 94.154 * img[1] - 18.285 * img[2]) / 256.\n","    return np.array([y, cb, cr]).transpose([1, 2, 0])\n","\n","\n","def convert_ycbcr_to_rgb(img, dim_order='hwc'):\n","    if dim_order == 'hwc':\n","        r = 298.082 * img[..., 0] / 256. + 408.583 * img[..., 2] / 256. - 222.921\n","        g = 298.082 * img[..., 0] / 256. - 100.291 * img[..., 1] / 256. - 208.120 * img[..., 2] / 256. + 135.576\n","        b = 298.082 * img[..., 0] / 256. + 516.412 * img[..., 1] / 256. - 276.836\n","    else:\n","        r = 298.082 * img[0] / 256. + 408.583 * img[2] / 256. - 222.921\n","        g = 298.082 * img[0] / 256. - 100.291 * img[1] / 256. - 208.120 * img[2] / 256. + 135.576\n","        b = 298.082 * img[0] / 256. + 516.412 * img[1] / 256. - 276.836\n","    return np.array([r, g, b]).transpose([1, 2, 0])\n","\n","\n","def preprocess(img, device):\n","    img = np.array(img).astype(np.float32)\n","    ycbcr = convert_rgb_to_ycbcr(img)\n","    x = ycbcr[..., 0]\n","    x /= 255.\n","    x = torch.from_numpy(x).to(device)\n","    x = x.unsqueeze(0).unsqueeze(0)\n","    return x, ycbcr\n","\n","\n","def calc_psnr(img1, img2):\n","    return 10. * torch.log10(1. / torch.mean((img1 - img2) ** 2))\n","\n","\n","def calc_ssim(img1, img2, sd=1.5, C1=0.01**2, C2=0.03**2):\n","    mu1 = gaussian_filter(img1, sd)\n","    mu2 = gaussian_filter(img2, sd)\n","    mu1_sq = mu1 * mu1\n","    mu2_sq = mu2 * mu2\n","    mu1_mu2 = mu1 * mu2\n","    sigma1_sq = gaussian_filter(img1 * img1, sd) - mu1_sq\n","    sigma2_sq = gaussian_filter(img2 * img2, sd) - mu2_sq\n","    sigma12 = gaussian_filter(img1 * img2, sd) - mu1_mu2\n","    \n","    ssim_num = ((2 * mu1_mu2 + C1) * (2 * sigma12 + C2))\n","    ssim_den = ((mu1_sq + mu2_sq + C1) * (sigma1_sq + sigma2_sq + C2))\n","    ssim_map = ssim_num / ssim_den\n","    mssim = np.mean(ssim_map)\n","    \n","    return mssim\n","\n","\n","class AverageMeter(object):\n","    def __init__(self):\n","        self.reset()\n","\n","    def reset(self):\n","        self.val = 0\n","        self.avg = 0\n","        self.sum = 0\n","        self.count = 0\n","\n","    def update(self, val, n=1):\n","        self.val = val\n","        self.sum += val * n\n","        self.count += n\n","        self.avg = self.sum / self.count"],"execution_count":17,"outputs":[]},{"cell_type":"code","metadata":{"id":"3Dy7hj989Fv-","executionInfo":{"status":"ok","timestamp":1619852470085,"user_tz":-330,"elapsed":1494,"user":{"displayName":"ASHISH KUMAR 4-Yr B.Tech. Comp. Sci. and Engg, 2018-2022","photoUrl":"","userId":"09157645467553063630"}}},"source":["import os\n","import copy\n","\n","import torch\n","from torch import nn\n","import torch.optim as optim\n","import torch.backends.cudnn as cudnn\n","from torch.utils.data.dataloader import DataLoader\n","from tqdm import tqdm\n","\n","\n","def train(train_file, eval_file, outputs_dir, weights_file, scale, growth_rate=16, num_blocks=8, num_layers=8, patch_size=100, lr=1e-4, batch_size=1e-4, num_epochs=60, num_workers=8, seed=123):\n","    outputs_dir = os.path.join(outputs_dir, 'x{}'.format(scale))\n","\n","    if not os.path.exists(outputs_dir):\n","        os.makedirs(outputs_dir)\n","\n","    cudnn.benchmark = True\n","    device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n","\n","    torch.manual_seed(seed)\n","\n","    model = SRDenseNet(growth_rate=growth_rate, num_blocks=num_blocks, num_layers=num_layers).to(device)\n","\n","    if weights_file is not None:\n","        state_dict = model.state_dict()\n","        for n, p in torch.load(weights_file, map_location=lambda storage, loc: storage).items():\n","            if n in state_dict.keys():\n","                state_dict[n].copy_(p)\n","            else:\n","                raise KeyError(n)\n","\n","    criterion = nn.MSELoss()\n","    optimizer = optim.Adam(model.parameters(), lr=lr)\n","\n","    train_dataset = TrainDataset(train_file, patch_size=patch_size, scale=scale)\n","    train_dataloader = DataLoader(dataset=train_dataset,\n","                                  batch_size=batch_size,\n","                                  shuffle=True,\n","                                  num_workers=num_workers,\n","                                  pin_memory=True)\n","    eval_dataset = EvalDataset(eval_file)\n","    eval_dataloader = DataLoader(dataset=eval_dataset, batch_size=1)\n","\n","    best_weights = copy.deepcopy(model.state_dict())\n","    best_epoch = 0\n","    best_psnr = 0.0\n","\n","    for epoch in range(num_epochs):\n","        for param_group in optimizer.param_groups:\n","            param_group['lr'] = lr * (0.1 ** (epoch // int(num_epochs * 0.8)))\n","\n","        model.train()\n","        epoch_losses = AverageMeter()\n","\n","        with tqdm(total=(len(train_dataset) - len(train_dataset) % batch_size), ncols=80) as t:\n","            t.set_description('epoch: {}/{}'.format(epoch, num_epochs - 1))\n","\n","            for data in train_dataloader:\n","                inputs, labels = data\n","\n","                inputs = inputs.to(device)\n","                labels = labels.to(device)\n","\n","                preds = model(inputs)\n","\n","                loss = criterion(preds, labels)\n","\n","                epoch_losses.update(loss.item(), len(inputs))\n","\n","                optimizer.zero_grad()\n","                loss.backward()\n","                optimizer.step()\n","\n","                t.set_postfix(loss='{:.6f}'.format(epoch_losses.avg))\n","                t.update(len(inputs))\n","\n","        torch.save(model.state_dict(), os.path.join(outputs_dir, 'epoch_{}.pth'.format(epoch)))\n","\n","        model.eval()\n","        epoch_psnr = AverageMeter()\n","\n","        for data in eval_dataloader:\n","            inputs, labels = data\n","\n","            inputs = inputs.to(device)\n","            labels = labels.to(device)\n","\n","            with torch.no_grad():\n","                preds = model(inputs).clamp(0.0, 1.0)\n","\n","            preds = preds[:, :, scale:-scale, scale:-scale]\n","            labels = labels[:, :, scale:-scale, scale:-scale]\n","\n","            epoch_psnr.update(calc_psnr(preds, labels), len(inputs))\n","\n","        print('eval psnr: {:.2f}'.format(epoch_psnr.avg))\n","\n","        if epoch_psnr.avg > best_psnr:\n","            best_epoch = epoch\n","            best_psnr = epoch_psnr.avg\n","            best_weights = copy.deepcopy(model.state_dict())\n","\n","    print('best epoch: {}, psnr: {:.2f}'.format(best_epoch, best_psnr))\n","    torch.save(best_weights, os.path.join(outputs_dir, 'best.pth'))"],"execution_count":12,"outputs":[]},{"cell_type":"code","metadata":{"id":"3MZg9B5H9dqP","executionInfo":{"status":"ok","timestamp":1619852515561,"user_tz":-330,"elapsed":1265,"user":{"displayName":"ASHISH KUMAR 4-Yr B.Tech. Comp. Sci. and Engg, 2018-2022","photoUrl":"","userId":"09157645467553063630"}}},"source":["import torch\n","import torch.backends.cudnn as cudnn\n","import numpy as np\n","import PIL.Image as pil_image\n","\n","\n","def test(weights_file, image_file, scale, save=False, debug=False):\n","    cudnn.benchmark = True\n","    device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n","\n","    model = SRDenseNet().to(device)\n","\n","    state_dict = model.state_dict()\n","    for n, p in torch.load(weights_file, map_location=lambda storage, loc: storage).items():\n","        if n in state_dict.keys():\n","            state_dict[n].copy_(p)\n","        else:\n","            raise KeyError(n)\n","\n","    model.eval()\n","\n","    image = pil_image.open(image_file).convert('RGB')\n","    image_file = os.path.basename(image_file)\n","\n","    image_width = (image.width // scale) * scale\n","    image_height = (image.height // scale) * scale\n","\n","    hr = image.resize((image_width, image_height), resample=pil_image.BICUBIC)\n","    lr = hr.resize((hr.width // scale, hr.height // scale), resample=pil_image.BICUBIC)\n","    bicubic = lr.resize((lr.width * scale, lr.height * scale), resample=pil_image.BICUBIC)\n","\n","    lr, _ = preprocess(lr, device)\n","    hr, _ = preprocess(hr, device)\n","    _, ycbcr = preprocess(bicubic, device)\n","\n","    with torch.no_grad():\n","        preds = model(lr).clamp(0.0, 1.0)\n","\n","    psnr = calc_psnr(hr, preds)\n","    ssim = calc_ssim(hr, preds)\n","    if debug:\n","        print(f'PSNR/SSIM: {psnr:.2f}/{ssim:.4f}')\n","\n","    preds = preds.mul(255.0).cpu().numpy().squeeze(0).squeeze(0)\n","\n","    output = np.array([preds, ycbcr[..., 1], ycbcr[..., 2]]).transpose([1, 2, 0])\n","    output = np.clip(convert_ycbcr_to_rgb(output), 0.0, 255.0).astype(np.uint8)\n","    output = pil_image.fromarray(output)\n","    if save:\n","        save_path = f'/content/drive/Shareddrives/BTP Meets/results/Set5/{scale}x/{image_file}'\n","        output.save(save_path.replace('.', '_srdensenet.'))\n","    return float(psnr), float(ssim)"],"execution_count":14,"outputs":[]},{"cell_type":"code","metadata":{"id":"_bwrF5pk9vIA","executionInfo":{"status":"ok","timestamp":1619852591930,"user_tz":-330,"elapsed":1111,"user":{"displayName":"ASHISH KUMAR 4-Yr B.Tech. Comp. Sci. and Engg, 2018-2022","photoUrl":"","userId":"09157645467553063630"}}},"source":["import os\n","\n","def do_test(psnr, ssim, BASE_DIR, save=False, debug=False):\n","    scales = [4]\n","\n","    for file in os.listdir(BASE_DIR):\n","        if file.endswith(\".png\"):\n","            image_file_path = os.path.join(BASE_DIR, file)\n","            if debug:\n","                print(file)\n","            for scale in scales:\n","                if debug:\n","                    print(f\"Scale: {scale}\")\n","                result = test(f'/content/drive/Shareddrives/BTP Meets/models/srdensenet_x{scale}.pth', image_file_path, scale, save, debug)\n","                if scale not in psnr:\n","                    psnr[scale] = []\n","                if scale not in ssim:\n","                    ssim[scale] = []\n","                psnr[scale].append(result[0])\n","                ssim[scale].append(result[1])\n","            if debug:\n","                print()\n"],"execution_count":15,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HcfXJaQk-BD8","executionInfo":{"status":"ok","timestamp":1619852633413,"user_tz":-330,"elapsed":10570,"user":{"displayName":"ASHISH KUMAR 4-Yr B.Tech. Comp. Sci. and Engg, 2018-2022","photoUrl":"","userId":"09157645467553063630"}},"outputId":"0f406463-5d55-4ede-c01a-27ce4a92d7f7"},"source":["psnr = {}\n","ssim = {}\n","do_test(psnr, ssim, '/content/drive/Shareddrives/BTP Meets/datasets/test/Set5/', True, True)"],"execution_count":18,"outputs":[{"output_type":"stream","text":["head.png\n","Scale: 4\n","PSNR/SSIM: 32.99/0.7985\n","\n","butterfly.png\n","Scale: 4\n","PSNR/SSIM: 27.57/0.9019\n","\n","bird.png\n","Scale: 4\n","PSNR/SSIM: 34.04/0.9348\n","\n","baby.png\n","Scale: 4\n","PSNR/SSIM: 33.69/0.8941\n","\n","woman.png\n","Scale: 4\n","PSNR/SSIM: 30.29/0.9108\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"3YadilgF-Ev2","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1619852658255,"user_tz":-330,"elapsed":1147,"user":{"displayName":"ASHISH KUMAR 4-Yr B.Tech. Comp. Sci. and Engg, 2018-2022","photoUrl":"","userId":"09157645467553063630"}},"outputId":"a4cf47d2-8aa8-4add-e14f-e51f0ad1d42b"},"source":["import statistics\n","\n","scales = [4]\n","for scale in scales:\n","    print(f'Avg PSNR/SSIM {scale}x: {statistics.mean(psnr[scale]):.2f}/{statistics.mean(ssim[scale]):.4f}')"],"execution_count":21,"outputs":[{"output_type":"stream","text":["Avg PSNR/SSIM 4x: 31.72/0.8880\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5WsOAWZ4vaOW","executionInfo":{"status":"ok","timestamp":1619855893779,"user_tz":-330,"elapsed":3168331,"user":{"displayName":"ASHISH KUMAR 4-Yr B.Tech. Comp. Sci. and Engg, 2018-2022","photoUrl":"","userId":"09157645467553063630"}},"outputId":"b98fcf97-be98-4728-f528-aebf3c05bd10"},"source":["scales = [4]\n","\n","def calc_result(dataset):\n","    print()\n","    print(dataset)\n","    psnr = {}\n","    ssim = {}\n","    do_test(psnr, ssim, f'/content/drive/Shareddrives/BTP Meets/datasets/test/{dataset}/')\n","    for scale in scales:\n","        print(f'Avg PSNR/SSIM {scale}x: {statistics.mean(psnr[scale]):.2f}/{statistics.mean(ssim[scale]):.4f}')\n","\n","calc_result('Set14')\n","calc_result('BSDS100')\n","calc_result('Manga109')\n","calc_result('Urban100')"],"execution_count":23,"outputs":[{"output_type":"stream","text":["\n","Set14\n","Avg PSNR/SSIM 4x: 28.27/0.7812\n","\n","BSDS100\n","Avg PSNR/SSIM 4x: 28.39/0.7605\n","\n","Manga109\n","Avg PSNR/SSIM 4x: 30.19/0.9071\n","\n","Urban100\n","Avg PSNR/SSIM 4x: 25.89/0.7786\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"zxKS9tTPvha3"},"source":[""],"execution_count":null,"outputs":[]}]}