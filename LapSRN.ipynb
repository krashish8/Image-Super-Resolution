{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"BTP - LapSRN.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyO1jWJTJXlGTS0CrpzN4Gz+"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RZO9j3VF4Dao","executionInfo":{"status":"ok","timestamp":1619890446221,"user_tz":-330,"elapsed":1099,"user":{"displayName":"ASHISH KUMAR 4-Yr B.Tech. Comp. Sci. and Engg, 2018-2022","photoUrl":"","userId":"09157645467553063630"}},"outputId":"4a93f0a0-4ca5-4cd1-89eb-593da07eb70f"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"7WlHe3hc4f5I"},"source":["import torch.utils.data as data\n","import torch\n","import numpy as np\n","import h5py\n","\n","class DatasetFromHdf5(data.Dataset):\n","    def __init__(self, file_path):\n","        super(DatasetFromHdf5, self).__init__()\n","        hf = h5py.File(file_path)\n","        self.data = hf.get(\"data\")\n","        self.label_x2 = hf.get(\"label_x2\")\n","        self.label_x4 = hf.get(\"label_x4\")\n","\n","    def __getitem__(self, index):\n","        return torch.from_numpy(self.data[index,:,:,:]).float(), torch.from_numpy(self.label_x2[index,:,:,:]).float(), torch.from_numpy(self.label_x4[index,:,:,:]).float()\n","\n","    def __len__(self):\n","        return self.data.shape[0]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_B-O-yFd4pCd"},"source":["import torch\n","import torch.nn as nn\n","import numpy as np\n","import math\n","\n","def get_upsample_filter(size):\n","    \"\"\"Make a 2D bilinear kernel suitable for upsampling\"\"\"\n","    factor = (size + 1) // 2\n","    if size % 2 == 1:\n","        center = factor - 1\n","    else:\n","        center = factor - 0.5\n","    og = np.ogrid[:size, :size]\n","    filter = (1 - abs(og[0] - center) / factor) * \\\n","             (1 - abs(og[1] - center) / factor)\n","    return torch.from_numpy(filter).float()\n","\n","class _Conv_Block(nn.Module):    \n","    def __init__(self):\n","        super(_Conv_Block, self).__init__()\n","        \n","        self.cov_block = nn.Sequential(\n","            nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, stride=1, padding=1, bias=False),\n","            nn.LeakyReLU(0.2, inplace=True),\n","            nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, stride=1, padding=1, bias=False),\n","            nn.LeakyReLU(0.2, inplace=True),\n","            nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, stride=1, padding=1, bias=False),\n","            nn.LeakyReLU(0.2, inplace=True),\n","            nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, stride=1, padding=1, bias=False),\n","            nn.LeakyReLU(0.2, inplace=True),\n","            nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, stride=1, padding=1, bias=False),\n","            nn.LeakyReLU(0.2, inplace=True),\n","            nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, stride=1, padding=1, bias=False),\n","            nn.LeakyReLU(0.2, inplace=True),\n","            nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, stride=1, padding=1, bias=False),\n","            nn.LeakyReLU(0.2, inplace=True),\n","            nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, stride=1, padding=1, bias=False),\n","            nn.LeakyReLU(0.2, inplace=True),\n","            nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, stride=1, padding=1, bias=False),\n","            nn.LeakyReLU(0.2, inplace=True),\n","            nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, stride=1, padding=1, bias=False),\n","            nn.LeakyReLU(0.2, inplace=True),\n","            nn.ConvTranspose2d(in_channels=64, out_channels=64, kernel_size=4, stride=2, padding=1, bias=False),\n","            nn.LeakyReLU(0.2, inplace=True),\n","        )\n","        \n","    def forward(self, x):  \n","        output = self.cov_block(x)\n","        return output \n","\n","class LapSRN(nn.Module):\n","    def __init__(self):\n","        super(LapSRN, self).__init__()\n","        \n","        self.conv_input = nn.Conv2d(in_channels=1, out_channels=64, kernel_size=3, stride=1, padding=1, bias=False)\n","        self.relu = nn.LeakyReLU(0.2, inplace=True)\n","        \n","        self.convt_I1 = nn.ConvTranspose2d(in_channels=1, out_channels=1, kernel_size=4, stride=2, padding=1, bias=False)\n","        self.convt_R1 = nn.Conv2d(in_channels=64, out_channels=1, kernel_size=3, stride=1, padding=1, bias=False)\n","        self.convt_F1 = self.make_layer(_Conv_Block)\n","  \n","        self.convt_I2 = nn.ConvTranspose2d(in_channels=1, out_channels=1, kernel_size=4, stride=2, padding=1, bias=False)\n","        self.convt_R2 = nn.Conv2d(in_channels=64, out_channels=1, kernel_size=3, stride=1, padding=1, bias=False)\n","        self.convt_F2 = self.make_layer(_Conv_Block)        \n","        \n","        for m in self.modules():\n","            if isinstance(m, nn.Conv2d):\n","                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n","                m.weight.data.normal_(0, math.sqrt(2. / n))\n","                if m.bias is not None:\n","                    m.bias.data.zero_()\n","            if isinstance(m, nn.ConvTranspose2d):\n","                c1, c2, h, w = m.weight.data.size()\n","                weight = get_upsample_filter(h)\n","                m.weight.data = weight.view(1, 1, h, w).repeat(c1, c2, 1, 1)\n","                if m.bias is not None:\n","                    m.bias.data.zero_()\n","                    \n","    def make_layer(self, block):\n","        layers = []\n","        layers.append(block())\n","        return nn.Sequential(*layers)\n","\n","    def forward(self, x):    \n","        out = self.relu(self.conv_input(x))\n","        \n","        convt_F1 = self.convt_F1(out)\n","        convt_I1 = self.convt_I1(x)\n","        convt_R1 = self.convt_R1(convt_F1)\n","        HR_2x = convt_I1 + convt_R1\n","        \n","        convt_F2 = self.convt_F2(convt_F1)\n","        convt_I2 = self.convt_I2(HR_2x)\n","        convt_R2 = self.convt_R2(convt_F2)\n","        HR_4x = convt_I2 + convt_R2\n","       \n","        return HR_2x, HR_4x\n","        \n","class L1_Charbonnier_loss(nn.Module):\n","    \"\"\"L1 Charbonnierloss.\"\"\"\n","    def __init__(self):\n","        super(L1_Charbonnier_loss, self).__init__()\n","        self.eps = 1e-6\n","\n","    def forward(self, X, Y):\n","        diff = torch.add(X, -Y)\n","        error = torch.sqrt( diff * diff + self.eps )\n","        loss = torch.sum(error) \n","        return loss"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"nSwS5khR4rjx"},"source":["import torch\n","import numpy as np\n","\n","\n","def calc_patch_size(func):\n","    def wrapper(args):\n","        if args.scale == 2:\n","            args.patch_size = 10\n","        elif args.scale == 3:\n","            args.patch_size = 7\n","        elif args.scale == 4:\n","            args.patch_size = 6\n","        else:\n","            raise Exception('Scale Error', args.scale)\n","        return func(args)\n","    return wrapper\n","\n","\n","def convert_rgb_to_y(img, dim_order='hwc'):\n","    if dim_order == 'hwc':\n","        return 16. + (64.738 * img[..., 0] + 129.057 * img[..., 1] + 25.064 * img[..., 2]) / 256.\n","    else:\n","        return 16. + (64.738 * img[0] + 129.057 * img[1] + 25.064 * img[2]) / 256.\n","\n","\n","def convert_rgb_to_ycbcr(img, dim_order='hwc'):\n","    if dim_order == 'hwc':\n","        y = 16. + (64.738 * img[..., 0] + 129.057 * img[..., 1] + 25.064 * img[..., 2]) / 256.\n","        cb = 128. + (-37.945 * img[..., 0] - 74.494 * img[..., 1] + 112.439 * img[..., 2]) / 256.\n","        cr = 128. + (112.439 * img[..., 0] - 94.154 * img[..., 1] - 18.285 * img[..., 2]) / 256.\n","    else:\n","        y = 16. + (64.738 * img[0] + 129.057 * img[1] + 25.064 * img[2]) / 256.\n","        cb = 128. + (-37.945 * img[0] - 74.494 * img[1] + 112.439 * img[2]) / 256.\n","        cr = 128. + (112.439 * img[0] - 94.154 * img[1] - 18.285 * img[2]) / 256.\n","    return np.array([y, cb, cr]).transpose([1, 2, 0])\n","\n","\n","def convert_ycbcr_to_rgb(img, dim_order='hwc'):\n","    if dim_order == 'hwc':\n","        r = 298.082 * img[..., 0] / 256. + 408.583 * img[..., 2] / 256. - 222.921\n","        g = 298.082 * img[..., 0] / 256. - 100.291 * img[..., 1] / 256. - 208.120 * img[..., 2] / 256. + 135.576\n","        b = 298.082 * img[..., 0] / 256. + 516.412 * img[..., 1] / 256. - 276.836\n","    else:\n","        r = 298.082 * img[0] / 256. + 408.583 * img[2] / 256. - 222.921\n","        g = 298.082 * img[0] / 256. - 100.291 * img[1] / 256. - 208.120 * img[2] / 256. + 135.576\n","        b = 298.082 * img[0] / 256. + 516.412 * img[1] / 256. - 276.836\n","    return np.array([r, g, b]).transpose([1, 2, 0])\n","\n","\n","def preprocess(img, device):\n","    img = np.array(img).astype(np.float32)\n","    ycbcr = convert_rgb_to_ycbcr(img)\n","    x = ycbcr[..., 0]\n","    x /= 255.\n","    x = torch.from_numpy(x).to(device)\n","    x = x.unsqueeze(0).unsqueeze(0)\n","    return x, ycbcr\n","\n","\n","def calc_psnr(img1, img2):\n","    return 10. * torch.log10(1. / torch.mean((img1 - img2) ** 2))\n","\n","\n","from scipy.ndimage import gaussian_filter\n","\n","def calc_ssim(img1, img2, sd=1.5, C1=0.01**2, C2=0.03**2):\n","    mu1 = gaussian_filter(img1, sd)\n","    mu2 = gaussian_filter(img2, sd)\n","    mu1_sq = mu1 * mu1\n","    mu2_sq = mu2 * mu2\n","    mu1_mu2 = mu1 * mu2\n","    sigma1_sq = gaussian_filter(img1 * img1, sd) - mu1_sq\n","    sigma2_sq = gaussian_filter(img2 * img2, sd) - mu2_sq\n","    sigma12 = gaussian_filter(img1 * img2, sd) - mu1_mu2\n","    \n","    ssim_num = ((2 * mu1_mu2 + C1) * (2 * sigma12 + C2))\n","    ssim_den = ((mu1_sq + mu2_sq + C1) * (sigma1_sq + sigma2_sq + C2))\n","    ssim_map = ssim_num / ssim_den\n","    mssim = np.mean(ssim_map)\n","    \n","    return mssim\n","\n","\n","class AverageMeter(object):\n","    def __init__(self):\n","        self.reset()\n","\n","    def reset(self):\n","        self.val = 0\n","        self.avg = 0\n","        self.sum = 0\n","        self.count = 0\n","\n","    def update(self, val, n=1):\n","        self.val = val\n","        self.sum += val * n\n","        self.count += n\n","        self.avg = self.sum / self.count\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"JyWg9lqU4trD"},"source":["import os\n","import torch\n","import random\n","import torch.backends.cudnn as cudnn\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.autograd import Variable\n","from torch.utils.data import DataLoader\n","\n","\n","def adjust_learning_rate(optimizer, epoch):\n","    \"\"\"Sets the learning rate to the initial LR decayed by 10 every 10 epochs\"\"\"\n","    lr = lr * (0.1 ** (epoch // step))\n","    return lr\n","\n","def train(training_data_loader, optimizer, model, criterion, epoch):\n","\n","    lr = adjust_learning_rate(optimizer, epoch-1)\n","\n","    for param_group in optimizer.param_groups:\n","        param_group[\"lr\"] = lr\n","\n","    print(\"Epoch={}, lr={}\".format(epoch, optimizer.param_groups[0][\"lr\"]))\n","\n","    model.train()\n","\n","    for iteration, batch in enumerate(training_data_loader, 1):\n","\n","        input, label_x2, label_x4 = Variable(batch[0]), Variable(batch[1], requires_grad=False), Variable(batch[2], requires_grad=False)\n","\n","        if cuda:\n","            input = input.cuda()\n","            label_x2 = label_x2.cuda()\n","            label_x4 = label_x4.cuda()\n","\n","        HR_2x, HR_4x = model(input)\n","\n","        loss_x2 = criterion(HR_2x, label_x2)\n","        loss_x4 = criterion(HR_4x, label_x4)\n","        loss = loss_x2 + loss_x4\n","\n","        optimizer.zero_grad()\n","\n","        loss_x2.backward(retain_graph=True)\n","\n","        loss_x4.backward()\n","\n","        optimizer.step()\n","\n","        if iteration%100 == 0:\n","            print(\"===> Epoch[{}]({}/{}): Loss: {:.10f}\".format(epoch, iteration, len(training_data_loader), loss.data[0]))\n","\n","def save_checkpoint(model, epoch):\n","    model_folder = \"checkpoint/\"\n","    model_out_path = model_folder + \"lapsrn_model_epoch_{}.pth\".format(epoch)\n","    state = {\"epoch\": epoch ,\"model\": model}\n","    if not os.path.exists(model_folder):\n","        os.makedirs(model_folder)\n","\n","    torch.save(state, model_out_path)\n","\n","    print(\"Checkpoint saved to {}\".format(model_out_path))\n","\n","\n","def train_main(batchSize=64, nEpochs=100, lr=1e-4, step=100, resume='', seed=123, start_epoch=1, threads=1, momentum=0.9, weight_decay=1e-4, pretrained=''):\n","    torch.manual_seed(seed)\n","    if cuda:\n","        torch.cuda.manual_seed(seed)\n","\n","    cudnn.benchmark = True\n","    device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n","\n","    print(\"===> Loading datasets\")\n","    train_set = DatasetFromHdf5(\"data/lap_pry_x4_small.h5\")\n","    training_data_loader = DataLoader(dataset=train_set, num_workers=threads, batch_size=batchSize, shuffle=True)\n","\n","    print(\"===> Building model\")\n","    model = LapSRN().to(device)\n","    criterion = L1_Charbonnier_loss().to(device)\n","\n","\n","    # optionally resume from a checkpoint\n","    if resume:\n","        if os.path.isfile(resume):\n","            print(\"=> loading checkpoint '{}'\".format(resume))\n","            checkpoint = torch.load(resume)\n","            start_epoch = checkpoint[\"epoch\"] + 1\n","            model.load_state_dict(checkpoint[\"model\"].state_dict())\n","        else:\n","            print(\"=> no checkpoint found at '{}'\".format(resume))\n","\n","    # optionally copy weights from a checkpoint\n","    if pretrained:\n","        if os.path.isfile(pretrained):\n","            print(\"=> loading model '{}'\".format(pretrained))\n","            weights = torch.load(pretrained)\n","            model.load_state_dict(weights['model'].state_dict())\n","        else:\n","            print(\"=> no model found at '{}'\".format(pretrained)) \n","\n","    print(\"===> Setting Optimizer\")\n","    optimizer = optim.Adam(model.parameters(), lr=lr)\n","\n","    print(\"===> Training\")\n","    for epoch in range(start_epoch, nEpochs + 1): \n","        train(training_data_loader, optimizer, model, criterion, epoch)\n","        save_checkpoint(model, epoch)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"MIB5vl2m5J6v"},"source":["import torch\n","import torch.backends.cudnn as cudnn\n","import numpy as np\n","import PIL.Image as pil_image\n","\n","\n","import torch\n","import torch.backends.cudnn as cudnn\n","import numpy as np\n","import PIL.Image as pil_image\n","\n","\n","def test(weights_file, image_file, scale, save=False, debug=False):\n","    cudnn.benchmark = True\n","    device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n","\n","    model = LapSRN()\n","    model.load_state_dict(torch.load(weights_file, map_location=device))\n","\n","    model.eval()\n","    model.to(device)\n","\n","    image = pil_image.open(image_file).convert('RGB')\n","    image_file = os.path.basename(image_file)\n","\n","    image_width = (image.width // scale) * scale\n","    image_height = (image.height // scale) * scale\n","\n","    hr = image.resize((image_width, image_height), resample=pil_image.BICUBIC)\n","    lr = hr.resize((hr.width // scale, hr.height // scale), resample=pil_image.BICUBIC)\n","    bicubic = lr.resize((lr.width * scale, lr.height * scale), resample=pil_image.BICUBIC)\n","\n","    lr, _ = preprocess(lr, device)\n","    hr, _ = preprocess(hr, device)\n","    _, ycbcr = preprocess(bicubic, device)\n","\n","    with torch.no_grad():\n","        preds = model(lr)\n","\n","    if (scale == 2):\n","        preds = preds[0]\n","    elif (scale == 4):\n","        preds = preds[1]\n","    else:\n","        assert(False)\n","    psnr = calc_psnr(hr, preds)\n","    ssim = calc_ssim(hr, preds)\n","\n","    if debug:\n","        print(f'PSNR/SSIM: {psnr:.2f}/{ssim:.4f}')\n","\n","    preds = preds.mul(255.0).cpu().numpy().squeeze(0).squeeze(0)\n","\n","    output = np.array([preds, ycbcr[..., 1], ycbcr[..., 2]]).transpose([1, 2, 0])\n","    output = np.clip(convert_ycbcr_to_rgb(output), 0.0, 255.0).astype(np.uint8)\n","    output = pil_image.fromarray(output)\n","    if save:\n","        save_path = f'/content/drive/Shareddrives/BTP Meets/results/Set5/{scale}x/{image_file}'\n","        output.save(save_path.replace('.', '_lapsrn.'))\n","    return float(psnr), float(ssim)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"mQnSCKYK5cas"},"source":["import os\n","\n","def do_test(psnr, ssim, BASE_DIR, save=False, debug=False):\n","    scales = [2, 4]\n","\n","    for file in os.listdir(BASE_DIR):\n","        if file.endswith(\".png\"):\n","            image_file_path = os.path.join(BASE_DIR, file)\n","            if debug:\n","                print(file)\n","            for scale in scales:\n","                if debug:\n","                    print(f\"Scale: {scale}\")\n","                result = test(f'/content/drive/Shareddrives/BTP Meets/models/weights-lapsrn.pth', image_file_path, scale, save, debug)\n","                if scale not in psnr:\n","                    psnr[scale] = []\n","                if scale not in ssim:\n","                    ssim[scale] = []\n","                psnr[scale].append(result[0])\n","                ssim[scale].append(result[1])\n","            if debug:\n","                print()\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OaKQNBso5y1a","executionInfo":{"status":"ok","timestamp":1619885808953,"user_tz":-330,"elapsed":22131,"user":{"displayName":"ASHISH KUMAR 4-Yr B.Tech. Comp. Sci. and Engg, 2018-2022","photoUrl":"","userId":"09157645467553063630"}},"outputId":"0e41ac0b-7e11-4ab9-d0af-0cd8094b0acb"},"source":["psnr = {}\n","ssim = {}\n","do_test(psnr, ssim, '/content/drive/Shareddrives/BTP Meets/datasets/test/Set5/', True, True)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["head.png\n","Scale: 2\n","PSNR/SSIM: 35.97/0.8899\n","Scale: 4\n","PSNR/SSIM: 32.94/0.7967\n","\n","butterfly.png\n","Scale: 2\n","PSNR/SSIM: 34.02/0.9723\n","Scale: 4\n","PSNR/SSIM: 27.30/0.8992\n","\n","bird.png\n","Scale: 2\n","PSNR/SSIM: 42.06/0.9886\n","Scale: 4\n","PSNR/SSIM: 33.48/0.9287\n","\n","baby.png\n","Scale: 2\n","PSNR/SSIM: 38.72/0.9671\n","Scale: 4\n","PSNR/SSIM: 33.64/0.8937\n","\n","woman.png\n","Scale: 2\n","PSNR/SSIM: 35.83/0.9719\n","Scale: 4\n","PSNR/SSIM: 30.37/0.9102\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"S02QmYlA7Q1s","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1619885813715,"user_tz":-330,"elapsed":1077,"user":{"displayName":"ASHISH KUMAR 4-Yr B.Tech. Comp. Sci. and Engg, 2018-2022","photoUrl":"","userId":"09157645467553063630"}},"outputId":"6cd47397-1567-4e6c-ea3e-dfb1b0f11a93"},"source":["import statistics\n","\n","scales = [2, 4]\n","for scale in scales:\n","    print(f'Avg PSNR/SSIM {scale}x: {statistics.mean(psnr[scale]):.2f}/{statistics.mean(ssim[scale]):.4f}')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Avg PSNR/SSIM 2x: 37.32/0.9580\n","Avg PSNR/SSIM 4x: 31.55/0.8857\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"oDgNWTl_t-sz","executionInfo":{"status":"ok","timestamp":1619888332915,"user_tz":-330,"elapsed":1233,"user":{"displayName":"ASHISH KUMAR 4-Yr B.Tech. Comp. Sci. and Engg, 2018-2022","photoUrl":"","userId":"09157645467553063630"}},"outputId":"6ab2346c-5b2f-45ae-acd7-5e7577843b03"},"source":["scales = [2, 4]\n","\n","def calc_result(dataset):\n","    print()\n","    print(dataset)\n","    psnr = {}\n","    ssim = {}\n","    do_test(psnr, ssim, f'/content/drive/Shareddrives/BTP Meets/datasets/test/{dataset}/')\n","    for scale in scales:\n","        print(f'Avg PSNR/SSIM {scale}x: {statistics.mean(psnr[scale]):.2f}/{statistics.mean(ssim[scale]):.4f}')\n","\n","calc_result('Set14')\n","calc_result('BSDS100')\n","calc_result('Manga109')\n","calc_result('Urban100')\n","\n","'''\n","Set14\n","Avg PSNR/SSIM 2x: 32.92/0.9126\n","Avg PSNR/SSIM 4x: 28.09/0.7773\n","\n","BSDS100\n","Avg PSNR/SSIM 2x: 33.53/0.9197\n","Avg PSNR/SSIM 4x: 28.25/0.7574\n","\n","Manga109\n","Avg PSNR/SSIM 2x: 37.19/0.9753\n","Avg PSNR/SSIM 4x: 29.40/0.8996\n","\n","Urban100\n","Avg PSNR/SSIM 2x: 30.38/0.9102\n","Avg PSNR/SSIM 4x: 25.31/0.7622\n","'''"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'\\nSet14\\nAvg PSNR/SSIM 2x: 32.92/0.9126\\nAvg PSNR/SSIM 4x: 28.09/0.7773\\n\\nBSDS100\\nAvg PSNR/SSIM 2x: 33.53/0.9197\\nAvg PSNR/SSIM 4x: 28.25/0.7574\\n'"]},"metadata":{"tags":[]},"execution_count":22}]},{"cell_type":"code","metadata":{"id":"x0AIo4OOuCVI"},"source":[""],"execution_count":null,"outputs":[]}]}