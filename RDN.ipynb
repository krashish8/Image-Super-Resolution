{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"BTP - RDN.ipynb","provenance":[],"authorship_tag":"ABX9TyNpvWGrtVqTWli7FeQE8iy0"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RZO9j3VF4Dao","executionInfo":{"status":"ok","timestamp":1619851466062,"user_tz":-330,"elapsed":27107,"user":{"displayName":"ASHISH KUMAR 4-Yr B.Tech. Comp. Sci. and Engg, 2018-2022","photoUrl":"","userId":"09157645467553063630"}},"outputId":"1382d3c8-e94f-477c-cf51-c44e61ad923f"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"7WlHe3hc4f5I","executionInfo":{"status":"ok","timestamp":1619851469755,"user_tz":-330,"elapsed":30788,"user":{"displayName":"ASHISH KUMAR 4-Yr B.Tech. Comp. Sci. and Engg, 2018-2022","photoUrl":"","userId":"09157645467553063630"}}},"source":["import random\n","import h5py\n","import numpy as np\n","from torch.utils.data import Dataset\n","\n","\n","class TrainDataset(Dataset):\n","    def __init__(self, h5_file, patch_size, scale):\n","        super(TrainDataset, self).__init__()\n","        self.h5_file = h5_file\n","        self.patch_size = patch_size\n","        self.scale = scale\n","\n","    @staticmethod\n","    def random_crop(lr, hr, size, scale):\n","        lr_left = random.randint(0, lr.shape[1] - size)\n","        lr_right = lr_left + size\n","        lr_top = random.randint(0, lr.shape[0] - size)\n","        lr_bottom = lr_top + size\n","        hr_left = lr_left * scale\n","        hr_right = lr_right * scale\n","        hr_top = lr_top * scale\n","        hr_bottom = lr_bottom * scale\n","        lr = lr[lr_top:lr_bottom, lr_left:lr_right]\n","        hr = hr[hr_top:hr_bottom, hr_left:hr_right]\n","        return lr, hr\n","\n","    @staticmethod\n","    def random_horizontal_flip(lr, hr):\n","        if random.random() < 0.5:\n","            lr = lr[:, ::-1, :].copy()\n","            hr = hr[:, ::-1, :].copy()\n","        return lr, hr\n","\n","    @staticmethod\n","    def random_vertical_flip(lr, hr):\n","        if random.random() < 0.5:\n","            lr = lr[::-1, :, :].copy()\n","            hr = hr[::-1, :, :].copy()\n","        return lr, hr\n","\n","    @staticmethod\n","    def random_rotate_90(lr, hr):\n","        if random.random() < 0.5:\n","            lr = np.rot90(lr, axes=(1, 0)).copy()\n","            hr = np.rot90(hr, axes=(1, 0)).copy()\n","        return lr, hr\n","\n","    def __getitem__(self, idx):\n","        with h5py.File(self.h5_file, 'r') as f:\n","            lr = f['lr'][str(idx)][::]\n","            hr = f['hr'][str(idx)][::]\n","            lr, hr = self.random_crop(lr, hr, self.patch_size, self.scale)\n","            lr, hr = self.random_horizontal_flip(lr, hr)\n","            lr, hr = self.random_vertical_flip(lr, hr)\n","            lr, hr = self.random_rotate_90(lr, hr)\n","            lr = lr.astype(np.float32).transpose([2, 0, 1]) / 255.0\n","            hr = hr.astype(np.float32).transpose([2, 0, 1]) / 255.0\n","            return lr, hr\n","\n","    def __len__(self):\n","        with h5py.File(self.h5_file, 'r') as f:\n","            return len(f['lr'])\n","\n","\n","class EvalDataset(Dataset):\n","    def __init__(self, h5_file):\n","        super(EvalDataset, self).__init__()\n","        self.h5_file = h5_file\n","\n","    def __getitem__(self, idx):\n","        with h5py.File(self.h5_file, 'r') as f:\n","            lr = f['lr'][str(idx)][::].astype(np.float32).transpose([2, 0, 1]) / 255.0\n","            hr = f['hr'][str(idx)][::].astype(np.float32).transpose([2, 0, 1]) / 255.0\n","            return lr, hr\n","\n","    def __len__(self):\n","        with h5py.File(self.h5_file, 'r') as f:\n","            return len(f['lr'])"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"_B-O-yFd4pCd","executionInfo":{"status":"ok","timestamp":1619851469759,"user_tz":-330,"elapsed":30782,"user":{"displayName":"ASHISH KUMAR 4-Yr B.Tech. Comp. Sci. and Engg, 2018-2022","photoUrl":"","userId":"09157645467553063630"}}},"source":["\n","import torch\n","from torch import nn\n","\n","\n","class DenseLayer(nn.Module):\n","    def __init__(self, in_channels, out_channels):\n","        super(DenseLayer, self).__init__()\n","        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=3 // 2)\n","        self.relu = nn.ReLU(inplace=True)\n","\n","    def forward(self, x):\n","        return torch.cat([x, self.relu(self.conv(x))], 1)\n","\n","\n","class RDB(nn.Module):\n","    def __init__(self, in_channels, growth_rate, num_layers):\n","        super(RDB, self).__init__()\n","        self.layers = nn.Sequential(*[DenseLayer(in_channels + growth_rate * i, growth_rate) for i in range(num_layers)])\n","\n","        # local feature fusion\n","        self.lff = nn.Conv2d(in_channels + growth_rate * num_layers, growth_rate, kernel_size=1)\n","\n","    def forward(self, x):\n","        return x + self.lff(self.layers(x))  # local residual learning\n","\n","\n","class RDN(nn.Module):\n","    def __init__(self, scale_factor, num_channels, num_features, growth_rate, num_blocks, num_layers):\n","        super(RDN, self).__init__()\n","        self.G0 = num_features\n","        self.G = growth_rate\n","        self.D = num_blocks\n","        self.C = num_layers\n","\n","        # shallow feature extraction\n","        self.sfe1 = nn.Conv2d(num_channels, num_features, kernel_size=3, padding=3 // 2)\n","        self.sfe2 = nn.Conv2d(num_features, num_features, kernel_size=3, padding=3 // 2)\n","\n","        # residual dense blocks\n","        self.rdbs = nn.ModuleList([RDB(self.G0, self.G, self.C)])\n","        for _ in range(self.D - 1):\n","            self.rdbs.append(RDB(self.G, self.G, self.C))\n","\n","        # global feature fusion\n","        self.gff = nn.Sequential(\n","            nn.Conv2d(self.G * self.D, self.G0, kernel_size=1),\n","            nn.Conv2d(self.G0, self.G0, kernel_size=3, padding=3 // 2)\n","        )\n","\n","        # up-sampling\n","        assert 2 <= scale_factor <= 4\n","        if scale_factor == 2 or scale_factor == 4:\n","            self.upscale = []\n","            for _ in range(scale_factor // 2):\n","                self.upscale.extend([nn.Conv2d(self.G0, self.G0 * (2 ** 2), kernel_size=3, padding=3 // 2),\n","                                     nn.PixelShuffle(2)])\n","            self.upscale = nn.Sequential(*self.upscale)\n","        else:\n","            self.upscale = nn.Sequential(\n","                nn.Conv2d(self.G0, self.G0 * (scale_factor ** 2), kernel_size=3, padding=3 // 2),\n","                nn.PixelShuffle(scale_factor)\n","            )\n","\n","        self.output = nn.Conv2d(self.G0, num_channels, kernel_size=3, padding=3 // 2)\n","\n","    def forward(self, x):\n","        sfe1 = self.sfe1(x)\n","        sfe2 = self.sfe2(sfe1)\n","\n","        x = sfe2\n","        local_features = []\n","        for i in range(self.D):\n","            x = self.rdbs[i](x)\n","            local_features.append(x)\n","\n","        x = self.gff(torch.cat(local_features, 1)) + sfe1  # global residual learning\n","        x = self.upscale(x)\n","        x = self.output(x)\n","        return x"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"nSwS5khR4rjx","executionInfo":{"status":"ok","timestamp":1619851654351,"user_tz":-330,"elapsed":1084,"user":{"displayName":"ASHISH KUMAR 4-Yr B.Tech. Comp. Sci. and Engg, 2018-2022","photoUrl":"","userId":"09157645467553063630"}}},"source":["import torch\n","import numpy as np\n","from scipy.ndimage import gaussian_filter\n","\n","\n","def convert_rgb_to_y(img, dim_order='hwc'):\n","    if dim_order == 'hwc':\n","        return 16. + (64.738 * img[..., 0] + 129.057 * img[..., 1] + 25.064 * img[..., 2]) / 256.\n","    else:\n","        return 16. + (64.738 * img[0] + 129.057 * img[1] + 25.064 * img[2]) / 256.\n","\n","\n","def denormalize(img):\n","    img = img.mul(255.0).clamp(0.0, 255.0)\n","    return img\n","\n","\n","def preprocess(img, device):\n","    img = np.array(img).astype(np.float32)\n","    ycbcr = convert_rgb_to_ycbcr(img)\n","    x = ycbcr[..., 0]\n","    x /= 255.\n","    x = torch.from_numpy(x).to(device)\n","    x = x.unsqueeze(0).unsqueeze(0)\n","    return x, ycbcr\n","\n","\n","def calc_psnr(img1, img2, max=255.0):\n","    return 10. * ((max ** 2) / ((img1 - img2) ** 2).mean()).log10()\n","\n","\n","def calc_ssim(img1, img2, sd=1.5, C1=0.01**2, C2=0.03**2):\n","    img1 = img1.cpu()\n","    img2 = img2.cpu()\n","    mu1 = gaussian_filter(img1, sd)\n","    mu2 = gaussian_filter(img2, sd)\n","    mu1_sq = mu1 * mu1\n","    mu2_sq = mu2 * mu2\n","    mu1_mu2 = mu1 * mu2\n","    sigma1_sq = gaussian_filter(img1 * img1, sd) - mu1_sq\n","    sigma2_sq = gaussian_filter(img2 * img2, sd) - mu2_sq\n","    sigma12 = gaussian_filter(img1 * img2, sd) - mu1_mu2\n","    \n","    ssim_num = ((2 * mu1_mu2 + C1) * (2 * sigma12 + C2))\n","    ssim_den = ((mu1_sq + mu2_sq + C1) * (sigma1_sq + sigma2_sq + C2))\n","    ssim_map = ssim_num / ssim_den\n","    mssim = np.mean(ssim_map)\n","    \n","    return mssim\n","\n","\n","class AverageMeter(object):\n","    def __init__(self):\n","        self.reset()\n","\n","    def reset(self):\n","        self.val = 0\n","        self.avg = 0\n","        self.sum = 0\n","        self.count = 0\n","\n","    def update(self, val, n=1):\n","        self.val = val\n","        self.sum += val * n\n","        self.count += n\n","        self.avg = self.sum / self.count"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"id":"JyWg9lqU4trD","executionInfo":{"status":"ok","timestamp":1619851469761,"user_tz":-330,"elapsed":30762,"user":{"displayName":"ASHISH KUMAR 4-Yr B.Tech. Comp. Sci. and Engg, 2018-2022","photoUrl":"","userId":"09157645467553063630"}}},"source":["import os\n","import copy\n","\n","import torch\n","from torch import nn\n","import torch.optim as optim\n","import torch.backends.cudnn as cudnn\n","from torch.utils.data.dataloader import DataLoader\n","from tqdm import tqdm\n","\n","\n","def train(train_file, eval_file, outputs_dir, weights_file, scale, num_features=64, growth_rate=64, num_blocks=16, num_layers=8, patch_size=32, lr=1e-4, batch_size=16, num_epochs=800, num_workers=8, seed=123):\n","    outputs_dir = os.path.join(outputs_dir, 'x{}'.format(scale))\n","\n","    if not os.path.exists(outputs_dir):\n","        os.makedirs(outputs_dir)\n","\n","    cudnn.benchmark = True\n","    device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n","\n","    torch.manual_seed(seed)\n","\n","    model = RDN(scale_factor=scale,\n","                num_channels=3,\n","                num_features=num_features,\n","                growth_rate=growth_rate,\n","                num_blocks=num_blocks,\n","                num_layers=num_layers).to(device)\n","\n","    if weights_file is not None:\n","        state_dict = model.state_dict()\n","        for n, p in torch.load(weights_file, map_location=lambda storage, loc: storage).items():\n","            if n in state_dict.keys():\n","                state_dict[n].copy_(p)\n","            else:\n","                raise KeyError(n)\n","\n","    criterion = nn.L1Loss()\n","    optimizer = optim.Adam(model.parameters(), lr=lr)\n","\n","    train_dataset = TrainDataset(train_file, patch_size=patch_size, scale=scale)\n","    train_dataloader = DataLoader(dataset=train_dataset,\n","                                  batch_size=batch_size,\n","                                  shuffle=True,\n","                                  num_workers=num_workers,\n","                                  pin_memory=True)\n","    eval_dataset = EvalDataset(eval_file)\n","    eval_dataloader = DataLoader(dataset=eval_dataset, batch_size=1)\n","\n","    best_weights = copy.deepcopy(model.state_dict())\n","    best_epoch = 0\n","    best_psnr = 0.0\n","\n","    for epoch in range(num_epochs):\n","        for param_group in optimizer.param_groups:\n","            param_group['lr'] = lr * (0.1 ** (epoch // int(num_epochs * 0.8)))\n","\n","        model.train()\n","        epoch_losses = AverageMeter()\n","\n","        with tqdm(total=(len(train_dataset) - len(train_dataset) % batch_size), ncols=80) as t:\n","            t.set_description('epoch: {}/{}'.format(epoch, num_epochs - 1))\n","\n","            for data in train_dataloader:\n","                inputs, labels = data\n","\n","                inputs = inputs.to(device)\n","                labels = labels.to(device)\n","\n","                preds = model(inputs)\n","\n","                loss = criterion(preds, labels)\n","\n","                epoch_losses.update(loss.item(), len(inputs))\n","\n","                optimizer.zero_grad()\n","                loss.backward()\n","                optimizer.step()\n","\n","                t.set_postfix(loss='{:.6f}'.format(epoch_losses.avg))\n","                t.update(len(inputs))\n","\n","        if (epoch + 1) % 10 == 0:\n","            torch.save(model.state_dict(), os.path.join(outputs_dir, 'epoch_{}.pth'.format(epoch)))\n","\n","        model.eval()\n","        epoch_psnr = AverageMeter()can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first.\n","\n","        for data in eval_dataloader:\n","            inputs, labels = data\n","\n","            inputs = inputs.to(device)\n","            labels = labels.to(device)\n","\n","            with torch.no_grad():\n","                preds = model(inputs)\n","\n","            preds = convert_rgb_to_y(denormalize(preds.squeeze(0)), dim_order='chw')\n","            labels = convert_rgb_to_y(denormalize(labels.squeeze(0)), dim_order='chw')\n","\n","            preds = preds[scale:-scale, scale:-scale]\n","            labels = labels[scale:-scale, scale:-scale]\n","\n","            epoch_psnr.update(calc_psnr(preds, labels), len(inputs))\n","\n","        print('eval psnr: {:.2f}'.format(epoch_psnr.avg))\n","\n","        if epoch_psnr.avg > best_psnr:\n","            best_epoch = epoch\n","            best_psnr = epoch_psnr.avg\n","            best_weights = copy.deepcopy(model.state_dict())\n","\n","    print('best epoch: {}, psnr: {:.2f}'.format(best_epoch, best_psnr))\n","    torch.save(best_weights, os.path.join(outputs_dir, 'best.pth'))"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"MIB5vl2m5J6v","executionInfo":{"status":"ok","timestamp":1619852131242,"user_tz":-330,"elapsed":1138,"user":{"displayName":"ASHISH KUMAR 4-Yr B.Tech. Comp. Sci. and Engg, 2018-2022","photoUrl":"","userId":"09157645467553063630"}}},"source":["import torch\n","import torch.backends.cudnn as cudnn\n","import numpy as np\n","import PIL.Image as pil_image\n","\n","\n","def test(weights_file, image_file, scale, save=False, debug=False, num_features=64, growth_rate=64, num_blocks=16, num_layers=8):\n","    cudnn.benchmark = True\n","    device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n","\n","    model = RDN(scale_factor=scale,\n","                num_channels=3,\n","                num_features=num_features,\n","                growth_rate=growth_rate,\n","                num_blocks=num_blocks,\n","                num_layers=num_layers).to(device)\n","\n","    state_dict = model.state_dict()\n","    for n, p in torch.load(weights_file, map_location=lambda storage, loc: storage).items():\n","        if n in state_dict.keys():\n","            state_dict[n].copy_(p)\n","        else:\n","            raise KeyError(n)\n","\n","    model.eval()\n","\n","    image = pil_image.open(image_file).convert('RGB')\n","    image_file = os.path.basename(image_file)\n","\n","    image_width = (image.width // scale) * scale\n","    image_height = (image.height // scale) * scale\n","\n","    hr = image.resize((image_width, image_height), resample=pil_image.BICUBIC)\n","    lr = hr.resize((hr.width // scale, hr.height // scale), resample=pil_image.BICUBIC)\n","    bicubic = lr.resize((lr.width * scale, lr.height * scale), resample=pil_image.BICUBIC)\n","\n","    lr = np.expand_dims(np.array(lr).astype(np.float32).transpose([2, 0, 1]), 0) / 255.0\n","    hr = np.expand_dims(np.array(hr).astype(np.float32).transpose([2, 0, 1]), 0) / 255.0\n","    lr = torch.from_numpy(lr).to(device)\n","    hr = torch.from_numpy(hr).to(device)\n","\n","    with torch.no_grad():\n","        preds = model(lr).squeeze(0)\n","\n","    preds_y = convert_rgb_to_y(denormalize(preds), dim_order='chw')\n","    hr_y = convert_rgb_to_y(denormalize(hr.squeeze(0)), dim_order='chw')\n","\n","    preds_y = preds_y[scale:-scale, scale:-scale]\n","    hr_y = hr_y[scale:-scale, scale:-scale]\n","\n","    psnr = calc_psnr(hr_y, preds_y)\n","    ssim = calc_ssim(hr_y, preds_y)\n","    if debug:\n","        print(f'PSNR/SSIM: {psnr:.2f}/{ssim:.4f}')\n","\n","    output = pil_image.fromarray(denormalize(preds).permute(1, 2, 0).byte().cpu().numpy())\n","    if save:\n","        save_path = f'/content/drive/Shareddrives/BTP Meets/results/Set5/{scale}x/{image_file}'\n","        output.save(save_path.replace('.', '_rdn.'))\n","    return float(psnr), float(ssim)"],"execution_count":28,"outputs":[]},{"cell_type":"code","metadata":{"id":"PXcgjlwgs69h","executionInfo":{"status":"ok","timestamp":1619852158371,"user_tz":-330,"elapsed":1190,"user":{"displayName":"ASHISH KUMAR 4-Yr B.Tech. Comp. Sci. and Engg, 2018-2022","photoUrl":"","userId":"09157645467553063630"}}},"source":["import os\n","\n","def do_test(psnr, ssim, BASE_DIR, save=False, debug=False):\n","    scales = [2, 3, 4]\n","\n","    for file in os.listdir(BASE_DIR):\n","        if file.endswith(\".png\"):\n","            image_file_path = os.path.join(BASE_DIR, file)\n","            if debug:\n","                print(file)\n","            for scale in scales:\n","                if debug:\n","                    print(f\"Scale: {scale}\")\n","                result = test(f'/content/drive/Shareddrives/BTP Meets/models/rdn_x{scale}.pth', image_file_path, scale, save, debug)\n","                if scale not in psnr:\n","                    psnr[scale] = []\n","                if scale not in ssim:\n","                    ssim[scale] = []\n","                psnr[scale].append(result[0])\n","                ssim[scale].append(result[1])\n","            if debug:\n","                print()\n"],"execution_count":31,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OaKQNBso5y1a","executionInfo":{"status":"ok","timestamp":1619852170204,"user_tz":-330,"elapsed":12810,"user":{"displayName":"ASHISH KUMAR 4-Yr B.Tech. Comp. Sci. and Engg, 2018-2022","photoUrl":"","userId":"09157645467553063630"}},"outputId":"5327338d-a9bf-43ef-f6a3-97f68043c63b"},"source":["psnr = {}\n","ssim = {}\n","do_test(psnr, ssim, '/content/drive/Shareddrives/BTP Meets/datasets/test/Set5/', True, True)"],"execution_count":32,"outputs":[{"output_type":"stream","text":["head.png\n","Scale: 2\n","PSNR/SSIM: 36.10/0.7394\n","Scale: 3\n","PSNR/SSIM: 35.63/0.6330\n","Scale: 4\n","PSNR/SSIM: 33.05/0.5009\n","\n","butterfly.png\n","Scale: 2\n","PSNR/SSIM: 35.70/0.9186\n","Scale: 3\n","PSNR/SSIM: 30.95/0.8491\n","Scale: 4\n","PSNR/SSIM: 28.91/0.7935\n","\n","bird.png\n","Scale: 2\n","PSNR/SSIM: 43.54/0.9434\n","Scale: 3\n","PSNR/SSIM: 37.64/0.8618\n","Scale: 4\n","PSNR/SSIM: 35.58/0.8206\n","\n","baby.png\n","Scale: 2\n","PSNR/SSIM: 38.99/0.8841\n","Scale: 3\n","PSNR/SSIM: 36.53/0.7736\n","Scale: 4\n","PSNR/SSIM: 33.87/0.6531\n","\n","woman.png\n","Scale: 2\n","PSNR/SSIM: 36.55/0.9228\n","Scale: 3\n","PSNR/SSIM: 32.90/0.8303\n","Scale: 4\n","PSNR/SSIM: 30.58/0.7645\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"S02QmYlA7Q1s","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1619852291686,"user_tz":-330,"elapsed":1012,"user":{"displayName":"ASHISH KUMAR 4-Yr B.Tech. Comp. Sci. and Engg, 2018-2022","photoUrl":"","userId":"09157645467553063630"}},"outputId":"036217ce-9701-42d5-c052-dd330813657b"},"source":["import statistics\n","\n","scales = [2, 3, 4]\n","for scale in scales:\n","    print(f'Avg PSNR/SSIM {scale}x: {statistics.mean(psnr[scale]):.2f}/{statistics.mean(ssim[scale]):.4f}')"],"execution_count":33,"outputs":[{"output_type":"stream","text":["Avg PSNR/SSIM 2x: 38.18/0.8817\n","Avg PSNR/SSIM 3x: 34.73/0.7896\n","Avg PSNR/SSIM 4x: 32.40/0.7065\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pN_gP_UluGnv","executionInfo":{"status":"ok","timestamp":1619854728250,"user_tz":-330,"elapsed":2432598,"user":{"displayName":"ASHISH KUMAR 4-Yr B.Tech. Comp. Sci. and Engg, 2018-2022","photoUrl":"","userId":"09157645467553063630"}},"outputId":"4e95fcf3-2d3b-4c83-c24f-d72722434155"},"source":["scales = [2, 3, 4]\n","\n","def calc_result(dataset):\n","    print()\n","    print(dataset)\n","    psnr = {}\n","    ssim = {}\n","    do_test(psnr, ssim, f'/content/drive/Shareddrives/BTP Meets/datasets/test/{dataset}/')\n","    for scale in scales:\n","        print(f'Avg PSNR/SSIM {scale}x: {statistics.mean(psnr[scale]):.2f}/{statistics.mean(ssim[scale]):.4f}')\n","\n","calc_result('Set14')\n","calc_result('BSDS100')\n","calc_result('Manga109')\n","calc_result('Urban100')"],"execution_count":34,"outputs":[{"output_type":"stream","text":["\n","Set14\n","Avg PSNR/SSIM 2x: 33.90/0.8048\n","Avg PSNR/SSIM 3x: 30.81/0.6671\n","Avg PSNR/SSIM 4x: 28.91/0.5654\n","\n","BSDS100\n","Avg PSNR/SSIM 2x: 34.19/0.8411\n","Avg PSNR/SSIM 3x: 29.49/0.6401\n","Avg PSNR/SSIM 4x: 28.62/0.5506\n","\n","Manga109\n","Avg PSNR/SSIM 2x: 39.50/0.8715\n","Avg PSNR/SSIM 3x: 33.12/0.6995\n","Avg PSNR/SSIM 4x: 31.42/0.6569\n","\n","Urban100\n","Avg PSNR/SSIM 2x: 32.46/0.8292\n","Avg PSNR/SSIM 3x: 28.63/0.6784\n","Avg PSNR/SSIM 4x: 26.40/0.5810\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"4E-AzKjouH2g"},"source":[""],"execution_count":null,"outputs":[]}]}