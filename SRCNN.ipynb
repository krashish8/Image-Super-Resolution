{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"BTP - SRCNN [GitHub].ipynb","provenance":[{"file_id":"1IkuwiLZ7CVO02YR45rlTHJltHqazGQd2","timestamp":1619359107646}],"collapsed_sections":[],"authorship_tag":"ABX9TyNdSfSH+fcTR/p7xAJn6dr/"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fFLPK_wRHANQ","executionInfo":{"status":"ok","timestamp":1619931826940,"user_tz":-330,"elapsed":27262,"user":{"displayName":"ASHISH KUMAR 4-Yr B.Tech. Comp. Sci. and Engg, 2018-2022","photoUrl":"","userId":"09157645467553063630"}},"outputId":"2a2e6870-32de-4cb9-d4de-118023bdd6ca"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"lgxC9jXUKWbw","executionInfo":{"status":"ok","timestamp":1619931830444,"user_tz":-330,"elapsed":6369,"user":{"displayName":"ASHISH KUMAR 4-Yr B.Tech. Comp. Sci. and Engg, 2018-2022","photoUrl":"","userId":"09157645467553063630"}}},"source":["import h5py\n","import numpy as np\n","from torch.utils.data import Dataset\n","\n","\n","class TrainDataset(Dataset):\n","    def __init__(self, h5_file):\n","        super(TrainDataset, self).__init__()\n","        self.h5_file = h5_file\n","\n","    def __getitem__(self, idx):\n","        with h5py.File(self.h5_file, 'r') as f:\n","            return np.expand_dims(f['lr'][idx] / 255., 0), np.expand_dims(f['hr'][idx] / 255., 0)\n","\n","    def __len__(self):\n","        with h5py.File(self.h5_file, 'r') as f:\n","            return len(f['lr'])\n","\n","\n","class EvalDataset(Dataset):\n","    def __init__(self, h5_file):\n","        super(EvalDataset, self).__init__()\n","        self.h5_file = h5_file\n","\n","    def __getitem__(self, idx):\n","        with h5py.File(self.h5_file, 'r') as f:\n","            return np.expand_dims(f['lr'][str(idx)][:, :] / 255., 0), np.expand_dims(f['hr'][str(idx)][:, :] / 255., 0)\n","\n","    def __len__(self):\n","        with h5py.File(self.h5_file, 'r') as f:\n","            return len(f['lr'])"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"NT0ghJg1LULm","executionInfo":{"status":"ok","timestamp":1619931830445,"user_tz":-330,"elapsed":5439,"user":{"displayName":"ASHISH KUMAR 4-Yr B.Tech. Comp. Sci. and Engg, 2018-2022","photoUrl":"","userId":"09157645467553063630"}}},"source":["from torch import nn\n","\n","\n","class SRCNN(nn.Module):\n","    def __init__(self, num_channels=1):\n","        super(SRCNN, self).__init__()\n","        self.conv1 = nn.Conv2d(num_channels, 64, kernel_size=9, padding=9 // 2)\n","        self.conv2 = nn.Conv2d(64, 32, kernel_size=5, padding=5 // 2)\n","        self.conv3 = nn.Conv2d(32, num_channels, kernel_size=5, padding=5 // 2)\n","        self.relu = nn.ReLU(inplace=True)\n","\n","    def forward(self, x):\n","        x = self.relu(self.conv1(x))\n","        x = self.relu(self.conv2(x))\n","        x = self.conv3(x)\n","        return x"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"f2t3uronpshS","executionInfo":{"status":"ok","timestamp":1619931869201,"user_tz":-330,"elapsed":1242,"user":{"displayName":"ASHISH KUMAR 4-Yr B.Tech. Comp. Sci. and Engg, 2018-2022","photoUrl":"","userId":"09157645467553063630"}}},"source":["import torch\n","import numpy as np\n","from scipy.ndimage import gaussian_filter\n","\n","\n","def calc_patch_size(func):\n","    def wrapper(args):\n","        if scale == 2:\n","            patch_size = 10\n","        elif scale == 3:\n","            patch_size = 7\n","        elif scale == 4:\n","            patch_size = 6\n","        else:\n","            raise Exception('Scale Error', scale)\n","        return func(args)\n","    return wrapper\n","\n","\n","def convert_rgb_to_y(img, dim_order='hwc'):\n","    if dim_order == 'hwc':\n","        return 16. + (64.738 * img[..., 0] + 129.057 * img[..., 1] + 25.064 * img[..., 2]) / 256.\n","    else:\n","        return 16. + (64.738 * img[0] + 129.057 * img[1] + 25.064 * img[2]) / 256.\n","\n","\n","def convert_rgb_to_ycbcr(img, dim_order='hwc'):\n","    if dim_order == 'hwc':\n","        y = 16. + (64.738 * img[..., 0] + 129.057 * img[..., 1] + 25.064 * img[..., 2]) / 256.\n","        cb = 128. + (-37.945 * img[..., 0] - 74.494 * img[..., 1] + 112.439 * img[..., 2]) / 256.\n","        cr = 128. + (112.439 * img[..., 0] - 94.154 * img[..., 1] - 18.285 * img[..., 2]) / 256.\n","    else:\n","        y = 16. + (64.738 * img[0] + 129.057 * img[1] + 25.064 * img[2]) / 256.\n","        cb = 128. + (-37.945 * img[0] - 74.494 * img[1] + 112.439 * img[2]) / 256.\n","        cr = 128. + (112.439 * img[0] - 94.154 * img[1] - 18.285 * img[2]) / 256.\n","    return np.array([y, cb, cr]).transpose([1, 2, 0])\n","\n","\n","def convert_ycbcr_to_rgb(img, dim_order='hwc'):\n","    if dim_order == 'hwc':\n","        r = 298.082 * img[..., 0] / 256. + 408.583 * img[..., 2] / 256. - 222.921\n","        g = 298.082 * img[..., 0] / 256. - 100.291 * img[..., 1] / 256. - 208.120 * img[..., 2] / 256. + 135.576\n","        b = 298.082 * img[..., 0] / 256. + 516.412 * img[..., 1] / 256. - 276.836\n","    else:\n","        r = 298.082 * img[0] / 256. + 408.583 * img[2] / 256. - 222.921\n","        g = 298.082 * img[0] / 256. - 100.291 * img[1] / 256. - 208.120 * img[2] / 256. + 135.576\n","        b = 298.082 * img[0] / 256. + 516.412 * img[1] / 256. - 276.836\n","    return np.array([r, g, b]).transpose([1, 2, 0])\n","\n","\n","def preprocess(img, device):\n","    img = np.array(img).astype(np.float32)\n","    ycbcr = convert_rgb_to_ycbcr(img)\n","    x = ycbcr[..., 0]\n","    x /= 255.\n","    x = torch.from_numpy(x).to(device)\n","    x = x.unsqueeze(0).unsqueeze(0)\n","    return x, ycbcr\n","\n","\n","def calc_psnr(img1, img2):\n","    return 10. * torch.log10(1. / torch.mean((img1 - img2) ** 2))\n","\n","\n","def calc_ssim(img1, img2, sd=1.5, C1=0.01**2, C2=0.03**2):\n","    mu1 = gaussian_filter(img1, sd)\n","    mu2 = gaussian_filter(img2, sd)\n","    mu1_sq = mu1 * mu1\n","    mu2_sq = mu2 * mu2\n","    mu1_mu2 = mu1 * mu2\n","    sigma1_sq = gaussian_filter(img1 * img1, sd) - mu1_sq\n","    sigma2_sq = gaussian_filter(img2 * img2, sd) - mu2_sq\n","    sigma12 = gaussian_filter(img1 * img2, sd) - mu1_mu2\n","    \n","    ssim_num = ((2 * mu1_mu2 + C1) * (2 * sigma12 + C2))\n","    ssim_den = ((mu1_sq + mu2_sq + C1) * (sigma1_sq + sigma2_sq + C2))\n","    ssim_map = ssim_num / ssim_den\n","    mssim = np.mean(ssim_map)\n","    \n","    return mssim\n","\n","\n","class AverageMeter(object):\n","    def __init__(self):\n","        self.reset()\n","\n","    def reset(self):\n","        self.val = 0\n","        self.avg = 0\n","        self.sum = 0\n","        self.count = 0\n","\n","    def update(self, val, n=1):\n","        self.val = val\n","        self.sum += val * n\n","        self.count += n\n","        self.avg = self.sum / self.count"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"id":"HNnVgQzcLVzX","executionInfo":{"status":"ok","timestamp":1619931830447,"user_tz":-330,"elapsed":3600,"user":{"displayName":"ASHISH KUMAR 4-Yr B.Tech. Comp. Sci. and Engg, 2018-2022","photoUrl":"","userId":"09157645467553063630"}}},"source":["import os\n","import copy\n","\n","import torch\n","from torch import nn\n","import torch.optim as optim\n","import torch.backends.cudnn as cudnn\n","from torch.utils.data.dataloader import DataLoader\n","from tqdm import tqdm\n","\n","\n","def train(train_file, eval_file, outputs_dir, scale, lr=1e-4, batch_size=16, num_epochs=400, num_workers=8, seed=123):\n","    outputs_dir = os.path.join(outputs_dir, 'x{}'.format(scale))\n","\n","    if not os.path.exists(outputs_dir):\n","        os.makedirs(outputs_dir)\n","\n","    cudnn.benchmark = True\n","    device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n","\n","    torch.manual_seed(seed)\n","\n","    model = SRCNN().to(device)\n","    criterion = nn.MSELoss()\n","    optimizer = optim.Adam([\n","        {'params': model.conv1.parameters()},\n","        {'params': model.conv2.parameters()},\n","        {'params': model.conv3.parameters(), 'lr': lr * 0.1}\n","    ], lr=lr)\n","\n","    train_dataset = TrainDataset(train_file)\n","    train_dataloader = DataLoader(dataset=train_dataset,\n","                                  batch_size=batch_size,\n","                                  shuffle=True,\n","                                  num_workers=num_workers,\n","                                  pin_memory=True,\n","                                  drop_last=True)\n","    eval_dataset = EvalDataset(eval_file)\n","    eval_dataloader = DataLoader(dataset=eval_dataset, batch_size=1)\n","\n","    best_weights = copy.deepcopy(model.state_dict())\n","    best_epoch = 0\n","    best_psnr = 0.0\n","\n","    for epoch in range(num_epochs):\n","        model.train()\n","        epoch_losses = AverageMeter()\n","\n","        with tqdm(total=(len(train_dataset) - len(train_dataset) % batch_size)) as t:\n","            t.set_description('epoch: {}/{}'.format(epoch, num_epochs - 1))\n","\n","            for data in train_dataloader:\n","                inputs, labels = data\n","\n","                inputs = inputs.to(device)\n","                labels = labels.to(device)\n","\n","                preds = model(inputs)\n","\n","                loss = criterion(preds, labels)\n","\n","                epoch_losses.update(loss.item(), len(inputs))\n","\n","                optimizer.zero_grad()\n","                loss.backward()\n","                optimizer.step()\n","\n","                t.set_postfix(loss='{:.6f}'.format(epoch_losses.avg))\n","                t.update(len(inputs))\n","\n","        torch.save(model.state_dict(), os.path.join(outputs_dir, 'epoch_{}.pth'.format(epoch)))\n","\n","        model.eval()\n","        epoch_psnr = AverageMeter()\n","\n","        for data in eval_dataloader:\n","            inputs, labels = data\n","\n","            inputs = inputs.to(device)\n","            labels = labels.to(device)\n","\n","            with torch.no_grad():\n","                preds = model(inputs).clamp(0.0, 1.0)\n","\n","            epoch_psnr.update(calc_psnr(preds, labels), len(inputs))\n","\n","        print('eval psnr: {:.2f}'.format(epoch_psnr.avg))\n","\n","        if epoch_psnr.avg > best_psnr:\n","            best_epoch = epoch\n","            best_psnr = epoch_psnr.avg\n","            best_weights = copy.deepcopy(model.state_dict())\n","\n","    print('best epoch: {}, psnr: {:.2f}'.format(best_epoch, best_psnr))\n","    torch.save(best_weights, os.path.join(outputs_dir, 'best.pth'))"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"Al7ir7KvLWw9","executionInfo":{"status":"ok","timestamp":1619932014465,"user_tz":-330,"elapsed":1333,"user":{"displayName":"ASHISH KUMAR 4-Yr B.Tech. Comp. Sci. and Engg, 2018-2022","photoUrl":"","userId":"09157645467553063630"}}},"source":["import torch\n","import torch.backends.cudnn as cudnn\n","import numpy as np\n","import PIL.Image as pil_image\n","\n","\n","def test(weights_file, image_file, scale, save=False, debug=False):\n","    cudnn.benchmark = True\n","    device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n","\n","    model = SRCNN().to(device)\n","\n","    state_dict = model.state_dict()\n","    for n, p in torch.load(weights_file, map_location=lambda storage, loc: storage).items():\n","        if n in state_dict.keys():\n","            state_dict[n].copy_(p)\n","        else:\n","            raise KeyError(n)\n","\n","    model.eval()\n","\n","    image = pil_image.open(image_file).convert('RGB')\n","    image_file = os.path.basename(image_file)\n","\n","    image_width = (image.width // scale) * scale\n","    image_height = (image.height // scale) * scale\n","\n","    hr = image.resize((image_width, image_height), resample=pil_image.BICUBIC)\n","    lr = hr.resize((hr.width // scale, hr.height // scale), resample=pil_image.BICUBIC)\n","    bicubic = lr.resize((lr.width * scale, lr.height * scale), resample=pil_image.BICUBIC)\n","\n","    lr, _ = preprocess(lr, device)\n","    hr, _ = preprocess(hr, device)\n","    bicubic, ycbcr = preprocess(bicubic, device)\n","\n","    with torch.no_grad():\n","        # Pre-upsampling\n","        preds = model(bicubic).clamp(0.0, 1.0)\n","\n","    psnr = calc_psnr(hr, preds)\n","    ssim = calc_ssim(hr, preds)\n","    if debug:\n","        print(f'PSNR/SSIM: {psnr:.2f}/{ssim:.4f}')\n","\n","    preds = preds.mul(255.0).cpu().numpy().squeeze(0).squeeze(0)\n","\n","    output = np.array([preds, ycbcr[..., 1], ycbcr[..., 2]]).transpose([1, 2, 0])\n","    output = np.clip(convert_ycbcr_to_rgb(output), 0.0, 255.0).astype(np.uint8)\n","    output = pil_image.fromarray(output)\n","    if save:\n","        save_path = f'/content/drive/Shareddrives/BTP Meets/results/Set5/{scale}x/{image_file}'\n","        output.save(save_path.replace('.', '_srcnn.'))\n","    return float(psnr), float(ssim)"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"id":"mRcUB0g_q7Ut","executionInfo":{"status":"ok","timestamp":1619932014467,"user_tz":-330,"elapsed":843,"user":{"displayName":"ASHISH KUMAR 4-Yr B.Tech. Comp. Sci. and Engg, 2018-2022","photoUrl":"","userId":"09157645467553063630"}}},"source":["import os\n","\n","def do_test(psnr, ssim, BASE_DIR, save=False, debug=False):\n","    scales = [2, 3, 4]\n","\n","    for file in os.listdir(BASE_DIR):\n","        if file.endswith(\".png\"):\n","            image_file_path = os.path.join(BASE_DIR, file)\n","            if debug:\n","                print(file)\n","            for scale in scales:\n","                if debug:\n","                    print(f\"Scale: {scale}\")\n","                result = test(f'/content/drive/Shareddrives/BTP Meets/models/srcnn_x{scale}.pth', image_file_path, scale, save, debug)\n","                if scale not in psnr:\n","                    psnr[scale] = []\n","                if scale not in ssim:\n","                    ssim[scale] = []\n","                psnr[scale].append(result[0])\n","                ssim[scale].append(result[1])\n","            if debug:\n","                print()\n"],"execution_count":12,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"M36fB84ci4uB","executionInfo":{"status":"ok","timestamp":1619932065964,"user_tz":-330,"elapsed":8235,"user":{"displayName":"ASHISH KUMAR 4-Yr B.Tech. Comp. Sci. and Engg, 2018-2022","photoUrl":"","userId":"09157645467553063630"}},"outputId":"3fc481a9-0766-4aa2-b52a-e8ff6fe71f49"},"source":["psnr = {}\n","ssim = {}\n","do_test(psnr, ssim, '/content/drive/Shareddrives/BTP Meets/datasets/test/Set5/', True, True)"],"execution_count":13,"outputs":[{"output_type":"stream","text":["head.png\n","Scale: 2\n","PSNR/SSIM: 35.75/0.8854\n","Scale: 3\n","PSNR/SSIM: 35.16/0.8704\n","Scale: 4\n","PSNR/SSIM: 32.44/0.7809\n","\n","butterfly.png\n","Scale: 2\n","PSNR/SSIM: 32.63/0.9639\n","Scale: 3\n","PSNR/SSIM: 28.46/0.9162\n","Scale: 4\n","PSNR/SSIM: 25.17/0.8413\n","\n","bird.png\n","Scale: 2\n","PSNR/SSIM: 41.01/0.9862\n","Scale: 3\n","PSNR/SSIM: 35.25/0.9522\n","Scale: 4\n","PSNR/SSIM: 32.04/0.9031\n","\n","baby.png\n","Scale: 2\n","PSNR/SSIM: 38.54/0.9656\n","Scale: 3\n","PSNR/SSIM: 36.11/0.9364\n","Scale: 4\n","PSNR/SSIM: 33.15/0.8846\n","\n","woman.png\n","Scale: 2\n","PSNR/SSIM: 35.30/0.9688\n","Scale: 3\n","PSNR/SSIM: 31.48/0.9303\n","Scale: 4\n","PSNR/SSIM: 28.47/0.8784\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xgpNECTXrecE","executionInfo":{"status":"ok","timestamp":1619932067765,"user_tz":-330,"elapsed":952,"user":{"displayName":"ASHISH KUMAR 4-Yr B.Tech. Comp. Sci. and Engg, 2018-2022","photoUrl":"","userId":"09157645467553063630"}},"outputId":"d7bf8eac-32a7-4a76-eb03-c2e9c81dcb74"},"source":["import statistics\n","\n","scales = [2, 3, 4]\n","for scale in scales:\n","    print(f'Avg PSNR/SSIM {scale}x: {statistics.mean(psnr[scale]):.2f}/{statistics.mean(ssim[scale]):.4f}')"],"execution_count":14,"outputs":[{"output_type":"stream","text":["Avg PSNR/SSIM 2x: 36.65/0.9540\n","Avg PSNR/SSIM 3x: 33.29/0.9211\n","Avg PSNR/SSIM 4x: 30.25/0.8577\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"6LAEREGLtnVt","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1619934284611,"user_tz":-330,"elapsed":2205067,"user":{"displayName":"ASHISH KUMAR 4-Yr B.Tech. Comp. Sci. and Engg, 2018-2022","photoUrl":"","userId":"09157645467553063630"}},"outputId":"057faedf-35d4-48c1-8055-32de2356ecb3"},"source":["scales = [2, 3, 4]\n","\n","def calc_result(dataset):\n","    print()\n","    print(dataset)\n","    psnr = {}\n","    ssim = {}\n","    do_test(psnr, ssim, f'/content/drive/Shareddrives/BTP Meets/datasets/test/{dataset}/')\n","    for scale in scales:\n","        print(f'Avg PSNR/SSIM {scale}x: {statistics.mean(psnr[scale]):.2f}/{statistics.mean(ssim[scale]):.4f}')\n","\n","calc_result('Set14')\n","calc_result('BSDS100')\n","calc_result('Manga109')\n","calc_result('Urban100')"],"execution_count":15,"outputs":[{"output_type":"stream","text":["\n","Set14\n","Avg PSNR/SSIM 2x: 32.34/0.9070\n","Avg PSNR/SSIM 3x: 29.55/0.8369\n","Avg PSNR/SSIM 4x: 27.25/0.7526\n","\n","BSDS100\n","Avg PSNR/SSIM 2x: 33.05/0.9144\n","Avg PSNR/SSIM 3x: 28.86/0.7999\n","Avg PSNR/SSIM 4x: 27.66/0.7371\n","\n","Manga109\n","Avg PSNR/SSIM 2x: 36.14/0.9705\n","Avg PSNR/SSIM 3x: 30.61/0.9163\n","Avg PSNR/SSIM 4x: 27.64/0.8573\n","\n","Urban100\n","Avg PSNR/SSIM 2x: 29.39/0.8951\n","Avg PSNR/SSIM 3x: 27.05/0.8216\n","Avg PSNR/SSIM 4x: 24.32/0.7168\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"kpImThMsjhdY"},"source":[""],"execution_count":null,"outputs":[]}]}