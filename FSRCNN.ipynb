{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"BTP - FSRCNN.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyO46jATBHHKllpFyzWuQdmw"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OU6R5XyNz5ZF","executionInfo":{"status":"ok","timestamp":1619849794488,"user_tz":-330,"elapsed":24460,"user":{"displayName":"ASHISH KUMAR 4-Yr B.Tech. Comp. Sci. and Engg, 2018-2022","photoUrl":"","userId":"09157645467553063630"}},"outputId":"9e5ff3a4-4849-4f3b-c0e0-990f5da69295"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"G5M3afYt1HGf"},"source":["import h5py\n","import numpy as np\n","from torch.utils.data import Dataset\n","\n","\n","class TrainDataset(Dataset):\n","    def __init__(self, h5_file):\n","        super(TrainDataset, self).__init__()\n","        self.h5_file = h5_file\n","\n","    def __getitem__(self, idx):\n","        with h5py.File(self.h5_file, 'r') as f:\n","            return np.expand_dims(f['lr'][idx] / 255., 0), np.expand_dims(f['hr'][idx] / 255., 0)\n","\n","    def __len__(self):\n","        with h5py.File(self.h5_file, 'r') as f:\n","            return len(f['lr'])\n","\n","\n","class EvalDataset(Dataset):\n","    def __init__(self, h5_file):\n","        super(EvalDataset, self).__init__()\n","        self.h5_file = h5_file\n","\n","    def __getitem__(self, idx):\n","        with h5py.File(self.h5_file, 'r') as f:\n","            return np.expand_dims(f['lr'][str(idx)][:, :] / 255., 0), np.expand_dims(f['hr'][str(idx)][:, :] / 255., 0)\n","\n","    def __len__(self):\n","        with h5py.File(self.h5_file, 'r') as f:\n","            return len(f['lr'])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"pTEJMnFx2Kic"},"source":["\n","import math\n","from torch import nn\n","\n","\n","class FSRCNN(nn.Module):\n","    def __init__(self, scale_factor, num_channels=1, d=56, s=12, m=4):\n","        super(FSRCNN, self).__init__()\n","        self.first_part = nn.Sequential(\n","            nn.Conv2d(num_channels, d, kernel_size=5, padding=5//2),\n","            nn.PReLU(d)\n","        )\n","        self.mid_part = [nn.Conv2d(d, s, kernel_size=1), nn.PReLU(s)]\n","        for _ in range(m):\n","            self.mid_part.extend([nn.Conv2d(s, s, kernel_size=3, padding=3//2), nn.PReLU(s)])\n","        self.mid_part.extend([nn.Conv2d(s, d, kernel_size=1), nn.PReLU(d)])\n","        self.mid_part = nn.Sequential(*self.mid_part)\n","        self.last_part = nn.ConvTranspose2d(d, num_channels, kernel_size=9, stride=scale_factor, padding=9//2,\n","                                            output_padding=scale_factor-1)\n","\n","        self._initialize_weights()\n","\n","    def _initialize_weights(self):\n","        for m in self.first_part:\n","            if isinstance(m, nn.Conv2d):\n","                nn.init.normal_(m.weight.data, mean=0.0, std=math.sqrt(2/(m.out_channels*m.weight.data[0][0].numel())))\n","                nn.init.zeros_(m.bias.data)\n","        for m in self.mid_part:\n","            if isinstance(m, nn.Conv2d):\n","                nn.init.normal_(m.weight.data, mean=0.0, std=math.sqrt(2/(m.out_channels*m.weight.data[0][0].numel())))\n","                nn.init.zeros_(m.bias.data)\n","        nn.init.normal_(self.last_part.weight.data, mean=0.0, std=0.001)\n","        nn.init.zeros_(self.last_part.bias.data)\n","\n","    def forward(self, x):\n","        x = self.first_part(x)\n","        x = self.mid_part(x)\n","        x = self.last_part(x)\n","        return x"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"YD-AKk7u2cC_"},"source":["import torch\n","import numpy as np\n","from scipy.ndimage import gaussian_filter\n","\n","\n","def calc_patch_size(func):\n","    def wrapper(args):\n","        if scale == 2:\n","            patch_size = 10\n","        elif scale == 3:\n","            patch_size = 7\n","        elif scale == 4:\n","            patch_size = 6\n","        else:\n","            raise Exception('Scale Error', scale)\n","        return func(args)\n","    return wrapper\n","\n","\n","def convert_rgb_to_y(img, dim_order='hwc'):\n","    if dim_order == 'hwc':\n","        return 16. + (64.738 * img[..., 0] + 129.057 * img[..., 1] + 25.064 * img[..., 2]) / 256.\n","    else:\n","        return 16. + (64.738 * img[0] + 129.057 * img[1] + 25.064 * img[2]) / 256.\n","\n","\n","def convert_rgb_to_ycbcr(img, dim_order='hwc'):\n","    if dim_order == 'hwc':\n","        y = 16. + (64.738 * img[..., 0] + 129.057 * img[..., 1] + 25.064 * img[..., 2]) / 256.\n","        cb = 128. + (-37.945 * img[..., 0] - 74.494 * img[..., 1] + 112.439 * img[..., 2]) / 256.\n","        cr = 128. + (112.439 * img[..., 0] - 94.154 * img[..., 1] - 18.285 * img[..., 2]) / 256.\n","    else:\n","        y = 16. + (64.738 * img[0] + 129.057 * img[1] + 25.064 * img[2]) / 256.\n","        cb = 128. + (-37.945 * img[0] - 74.494 * img[1] + 112.439 * img[2]) / 256.\n","        cr = 128. + (112.439 * img[0] - 94.154 * img[1] - 18.285 * img[2]) / 256.\n","    return np.array([y, cb, cr]).transpose([1, 2, 0])\n","\n","\n","def convert_ycbcr_to_rgb(img, dim_order='hwc'):\n","    if dim_order == 'hwc':\n","        r = 298.082 * img[..., 0] / 256. + 408.583 * img[..., 2] / 256. - 222.921\n","        g = 298.082 * img[..., 0] / 256. - 100.291 * img[..., 1] / 256. - 208.120 * img[..., 2] / 256. + 135.576\n","        b = 298.082 * img[..., 0] / 256. + 516.412 * img[..., 1] / 256. - 276.836\n","    else:\n","        r = 298.082 * img[0] / 256. + 408.583 * img[2] / 256. - 222.921\n","        g = 298.082 * img[0] / 256. - 100.291 * img[1] / 256. - 208.120 * img[2] / 256. + 135.576\n","        b = 298.082 * img[0] / 256. + 516.412 * img[1] / 256. - 276.836\n","    return np.array([r, g, b]).transpose([1, 2, 0])\n","\n","\n","def preprocess(img, device):\n","    img = np.array(img).astype(np.float32)\n","    ycbcr = convert_rgb_to_ycbcr(img)\n","    x = ycbcr[..., 0]\n","    x /= 255.\n","    x = torch.from_numpy(x).to(device)\n","    x = x.unsqueeze(0).unsqueeze(0)\n","    return x, ycbcr\n","\n","\n","def calc_psnr(img1, img2):\n","    return 10. * torch.log10(1. / torch.mean((img1 - img2) ** 2))\n","\n","\n","def calc_ssim(img1, img2, sd=1.5, C1=0.01**2, C2=0.03**2):\n","    mu1 = gaussian_filter(img1, sd)\n","    mu2 = gaussian_filter(img2, sd)\n","    mu1_sq = mu1 * mu1\n","    mu2_sq = mu2 * mu2\n","    mu1_mu2 = mu1 * mu2\n","    sigma1_sq = gaussian_filter(img1 * img1, sd) - mu1_sq\n","    sigma2_sq = gaussian_filter(img2 * img2, sd) - mu2_sq\n","    sigma12 = gaussian_filter(img1 * img2, sd) - mu1_mu2\n","    \n","    ssim_num = ((2 * mu1_mu2 + C1) * (2 * sigma12 + C2))\n","    ssim_den = ((mu1_sq + mu2_sq + C1) * (sigma1_sq + sigma2_sq + C2))\n","    ssim_map = ssim_num / ssim_den\n","    mssim = np.mean(ssim_map)\n","    \n","    return mssim\n","\n","\n","class AverageMeter(object):\n","    def __init__(self):\n","        self.reset()\n","\n","    def reset(self):\n","        self.val = 0\n","        self.avg = 0\n","        self.sum = 0\n","        self.count = 0\n","\n","    def update(self, val, n=1):\n","        self.val = val\n","        self.sum += val * n\n","        self.count += n\n","        self.avg = self.sum / self.count"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"VwWZoyJ62eee"},"source":["import os\n","import copy\n","\n","import torch\n","from torch import nn\n","import torch.optim as optim\n","import torch.backends.cudnn as cudnn\n","from torch.utils.data.dataloader import DataLoader\n","from tqdm import tqdm\n","\n","\n","def train(train_file, eval_file, outputs_dir, weights_file, scale, lr=1e-3, batch_size=16, num_epochs=20, num_workers=8, seed=123):\n","    if not os.path.exists(outputs_dir):\n","        os.makedirs(outputs_dir)\n","\n","    cudnn.benchmark = True\n","    device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n","\n","    torch.manual_seed(seed)\n","\n","    model = FSRCNN(scale_factor=scale).to(device)\n","    criterion = nn.MSELoss()\n","    optimizer = optim.Adam([\n","        {'params': model.first_part.parameters()},\n","        {'params': model.mid_part.parameters()},\n","        {'params': model.last_part.parameters(), 'lr': lr * 0.1}\n","    ], lr=lr)\n","\n","    train_dataset = TrainDataset(train_file)\n","    train_dataloader = DataLoader(dataset=train_dataset,\n","                                  batch_size=batch_size,\n","                                  shuffle=True,\n","                                  num_workers=num_workers,\n","                                  pin_memory=True)\n","    eval_dataset = EvalDataset(eval_file)\n","    eval_dataloader = DataLoader(dataset=eval_dataset, batch_size=1)\n","\n","    best_weights = copy.deepcopy(model.state_dict())\n","    best_epoch = 0\n","    best_psnr = 0.0\n","\n","    for epoch in range(num_epochs):\n","        model.train()\n","        epoch_losses = AverageMeter()\n","\n","        with tqdm(total=(len(train_dataset) - len(train_dataset) % batch_size), ncols=80) as t:\n","            t.set_description('epoch: {}/{}'.format(epoch, num_epochs - 1))\n","\n","            for data in train_dataloader:\n","                inputs, labels = data\n","\n","                inputs = inputs.to(device)\n","                labels = labels.to(device)\n","\n","                preds = model(inputs)\n","\n","                loss = criterion(preds, labels)\n","\n","                epoch_losses.update(loss.item(), len(inputs))\n","\n","                optimizer.zero_grad()\n","                loss.backward()\n","                optimizer.step()\n","\n","                t.set_postfix(loss='{:.6f}'.format(epoch_losses.avg))\n","                t.update(len(inputs))\n","\n","        torch.save(model.state_dict(), os.path.join(outputs_dir, 'epoch_{}.pth'.format(epoch)))\n","\n","        model.eval()\n","        epoch_psnr = AverageMeter()\n","\n","        for data in eval_dataloader:\n","            inputs, labels = data\n","\n","            inputs = inputs.to(device)\n","            labels = labels.to(device)\n","\n","            with torch.no_grad():\n","                preds = model(inputs).clamp(0.0, 1.0)\n","\n","            epoch_psnr.update(calc_psnr(preds, labels), len(inputs))\n","\n","        print('eval psnr: {:.2f}'.format(epoch_psnr.avg))\n","\n","        if epoch_psnr.avg > best_psnr:\n","            best_epoch = epoch\n","            best_psnr = epoch_psnr.avg\n","            best_weights = copy.deepcopy(model.state_dict())\n","\n","    print('best epoch: {}, psnr: {:.2f}'.format(best_epoch, best_psnr))\n","    torch.save(best_weights, os.path.join(outputs_dir, 'best.pth'))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"QYTmj_-F2zxK"},"source":["import torch\n","import torch.backends.cudnn as cudnn\n","import numpy as np\n","import PIL.Image as pil_image\n","\n","\n","def test(weights_file, image_file, scale, save=False, debug=False):\n","    cudnn.benchmark = True\n","    device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n","\n","    model = FSRCNN(scale_factor=scale).to(device)\n","\n","    state_dict = model.state_dict()\n","    for n, p in torch.load(weights_file, map_location=lambda storage, loc: storage).items():\n","        if n in state_dict.keys():\n","            state_dict[n].copy_(p)\n","        else:\n","            raise KeyError(n)\n","\n","    model.eval()\n","\n","    image = pil_image.open(image_file).convert('RGB')\n","    image_file = os.path.basename(image_file)\n","\n","    image_width = (image.width // scale) * scale\n","    image_height = (image.height // scale) * scale\n","\n","    hr = image.resize((image_width, image_height), resample=pil_image.BICUBIC)\n","    lr = hr.resize((hr.width // scale, hr.height // scale), resample=pil_image.BICUBIC)\n","    bicubic = lr.resize((lr.width * scale, lr.height * scale), resample=pil_image.BICUBIC)\n","\n","    lr, _ = preprocess(lr, device)\n","    hr, _ = preprocess(hr, device)\n","    _, ycbcr = preprocess(bicubic, device)\n","\n","    with torch.no_grad():\n","        preds = model(lr).clamp(0.0, 1.0)\n","\n","    psnr = calc_psnr(hr, preds)\n","    ssim = calc_ssim(hr, preds)\n","    if debug:\n","        print(f'PSNR/SSIM: {psnr:.2f}/{ssim:.4f}')\n","\n","    preds = preds.mul(255.0).cpu().numpy().squeeze(0).squeeze(0)\n","\n","    output = np.array([preds, ycbcr[..., 1], ycbcr[..., 2]]).transpose([1, 2, 0])\n","    output = np.clip(convert_ycbcr_to_rgb(output), 0.0, 255.0).astype(np.uint8)\n","    output = pil_image.fromarray(output)\n","    if save:\n","        save_path = f'/content/drive/Shareddrives/BTP Meets/results/Set5/{scale}x/{image_file}'\n","        output.save(save_path.replace('.', '_fsrcnn.'))\n","    return float(psnr), float(ssim)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Hg3LnSxJ3KLN"},"source":["import os\n","\n","def do_test(psnr, ssim, BASE_DIR, save=False, debug=False):\n","    scales = [2, 3, 4]\n","\n","    for file in os.listdir(BASE_DIR):\n","        if file.endswith(\".png\"):\n","            image_file_path = os.path.join(BASE_DIR, file)\n","            if debug:\n","                print(file)\n","            for scale in scales:\n","                if debug:\n","                    print(f\"Scale: {scale}\")\n","                result = test(f'/content/drive/Shareddrives/BTP Meets/models/fsrcnn_x{scale}.pth', image_file_path, scale, save, debug)\n","                if scale not in psnr:\n","                    psnr[scale] = []\n","                if scale not in ssim:\n","                    ssim[scale] = []\n","                psnr[scale].append(result[0])\n","                ssim[scale].append(result[1])\n","            if debug:\n","                print()\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YzIA23YK3Mvd","executionInfo":{"status":"ok","timestamp":1619849940568,"user_tz":-330,"elapsed":5868,"user":{"displayName":"ASHISH KUMAR 4-Yr B.Tech. Comp. Sci. and Engg, 2018-2022","photoUrl":"","userId":"09157645467553063630"}},"outputId":"39a4c125-7f44-4b95-e268-c78290b08100"},"source":["psnr = {}\n","ssim = {}\n","do_test(psnr, ssim, '/content/drive/Shareddrives/BTP Meets/datasets/test/Set5/', True, True)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["head.png\n","Scale: 2\n","PSNR/SSIM: 35.88/0.8878\n","Scale: 3\n","PSNR/SSIM: 35.03/0.8663\n","Scale: 4\n","PSNR/SSIM: 32.47/0.7791\n","\n","butterfly.png\n","Scale: 2\n","PSNR/SSIM: 33.54/0.9699\n","Scale: 3\n","PSNR/SSIM: 28.55/0.9160\n","Scale: 4\n","PSNR/SSIM: 25.33/0.8453\n","\n","bird.png\n","Scale: 2\n","PSNR/SSIM: 41.73/0.9881\n","Scale: 3\n","PSNR/SSIM: 35.15/0.9505\n","Scale: 4\n","PSNR/SSIM: 32.46/0.9073\n","\n","baby.png\n","Scale: 2\n","PSNR/SSIM: 38.69/0.9668\n","Scale: 3\n","PSNR/SSIM: 35.89/0.9313\n","Scale: 4\n","PSNR/SSIM: 33.14/0.8740\n","\n","woman.png\n","Scale: 2\n","PSNR/SSIM: 35.76/0.9713\n","Scale: 3\n","PSNR/SSIM: 31.46/0.9271\n","Scale: 4\n","PSNR/SSIM: 29.11/0.8825\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Am7RGD8k3erD","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1619849940569,"user_tz":-330,"elapsed":3886,"user":{"displayName":"ASHISH KUMAR 4-Yr B.Tech. Comp. Sci. and Engg, 2018-2022","photoUrl":"","userId":"09157645467553063630"}},"outputId":"939de315-3e56-4e73-c359-7c638efb2fa4"},"source":["import statistics\n","\n","scales = [2, 3, 4]\n","for scale in scales:\n","    print(f'Avg PSNR/SSIM {scale}x: {statistics.mean(psnr[scale]):.2f}/{statistics.mean(ssim[scale]):.4f}')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Avg PSNR/SSIM 2x: 37.12/0.9568\n","Avg PSNR/SSIM 3x: 33.22/0.9182\n","Avg PSNR/SSIM 4x: 30.50/0.8577\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mANfruQ6lH7S","executionInfo":{"status":"ok","timestamp":1619850632819,"user_tz":-330,"elapsed":686827,"user":{"displayName":"ASHISH KUMAR 4-Yr B.Tech. Comp. Sci. and Engg, 2018-2022","photoUrl":"","userId":"09157645467553063630"}},"outputId":"781e2d49-d685-4ed1-b0a5-b09fd965b1ed"},"source":["scales = [2, 3, 4]\n","\n","def calc_result(dataset):\n","    print()\n","    print(dataset)\n","    psnr = {}\n","    ssim = {}\n","    do_test(psnr, ssim, f'/content/drive/Shareddrives/BTP Meets/datasets/test/{dataset}/')\n","    for scale in scales:\n","        print(f'Avg PSNR/SSIM {scale}x: {statistics.mean(psnr[scale]):.2f}/{statistics.mean(ssim[scale]):.4f}')\n","\n","calc_result('Set14')\n","calc_result('BSDS100')\n","calc_result('Manga109')\n","calc_result('Urban100')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["\n","Set14\n","Avg PSNR/SSIM 2x: 32.68/0.9108\n","Avg PSNR/SSIM 3x: 29.57/0.8349\n","Avg PSNR/SSIM 4x: 27.42/0.7537\n","\n","BSDS100\n","Avg PSNR/SSIM 2x: 33.35/0.9177\n","Avg PSNR/SSIM 3x: 28.81/0.7980\n","Avg PSNR/SSIM 4x: 27.76/0.7382\n","\n","Manga109\n","Avg PSNR/SSIM 2x: 37.39/0.9740\n","Avg PSNR/SSIM 3x: 30.45/0.9100\n","Avg PSNR/SSIM 4x: 27.99/0.8497\n","\n","Urban100\n","Avg PSNR/SSIM 2x: 29.84/0.9021\n","Avg PSNR/SSIM 3x: 26.99/0.8178\n","Avg PSNR/SSIM 4x: 24.48/0.7206\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"GnqOwyOYlKMw"},"source":[""],"execution_count":null,"outputs":[]}]}