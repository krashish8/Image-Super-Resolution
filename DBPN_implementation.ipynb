{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import math\n",
    "\n",
    "class DenseBlock(torch.nn.Module):\n",
    "    def __init__(self, input_size, output_size, bias=True, activation='relu', norm='batch'):\n",
    "        super(DenseBlock, self).__init__()\n",
    "        self.fc = torch.nn.Linear(input_size, output_size, bias=bias)\n",
    "\n",
    "        self.norm = norm\n",
    "        if self.norm =='batch':\n",
    "            self.bn = torch.nn.BatchNorm1d(output_size)\n",
    "        elif self.norm == 'instance':\n",
    "            self.bn = torch.nn.InstanceNorm1d(output_size)\n",
    "\n",
    "        self.activation = activation\n",
    "        if self.activation == 'relu':\n",
    "            self.act = torch.nn.ReLU(True)\n",
    "        elif self.activation == 'prelu':\n",
    "            self.act = torch.nn.PReLU()\n",
    "        elif self.activation == 'lrelu':\n",
    "            self.act = torch.nn.LeakyReLU(0.2, True)\n",
    "        elif self.activation == 'tanh':\n",
    "            self.act = torch.nn.Tanh()\n",
    "        elif self.activation == 'sigmoid':\n",
    "            self.act = torch.nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.norm is not None:\n",
    "            out = self.bn(self.fc(x))\n",
    "        else:\n",
    "            out = self.fc(x)\n",
    "\n",
    "        if self.activation is not None:\n",
    "            return self.act(out)\n",
    "        else:\n",
    "            return out\n",
    "\n",
    "\n",
    "class ConvBlock(torch.nn.Module):\n",
    "    def __init__(self, input_size, output_size, kernel_size=3, stride=1, padding=1, bias=True, activation='prelu', norm=None):\n",
    "        super(ConvBlock, self).__init__()\n",
    "        self.conv = torch.nn.Conv2d(input_size, output_size, kernel_size, stride, padding, bias=bias)\n",
    "\n",
    "        self.norm = norm\n",
    "        if self.norm =='batch':\n",
    "            self.bn = torch.nn.BatchNorm2d(output_size)\n",
    "        elif self.norm == 'instance':\n",
    "            self.bn = torch.nn.InstanceNorm2d(output_size)\n",
    "\n",
    "        self.activation = activation\n",
    "        if self.activation == 'relu':\n",
    "            self.act = torch.nn.ReLU(True)\n",
    "        elif self.activation == 'prelu':\n",
    "            self.act = torch.nn.PReLU()\n",
    "        elif self.activation == 'lrelu':\n",
    "            self.act = torch.nn.LeakyReLU(0.2, True)\n",
    "        elif self.activation == 'tanh':\n",
    "            self.act = torch.nn.Tanh()\n",
    "        elif self.activation == 'sigmoid':\n",
    "            self.act = torch.nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.norm is not None:\n",
    "            out = self.bn(self.conv(x))\n",
    "        else:\n",
    "            out = self.conv(x)\n",
    "\n",
    "        if self.activation is not None:\n",
    "            return self.act(out)\n",
    "        else:\n",
    "            return out\n",
    "\n",
    "\n",
    "class DeconvBlock(torch.nn.Module):\n",
    "    def __init__(self, input_size, output_size, kernel_size=4, stride=2, padding=1, bias=True, activation='prelu', norm=None):\n",
    "        super(DeconvBlock, self).__init__()\n",
    "        self.deconv = torch.nn.ConvTranspose2d(input_size, output_size, kernel_size, stride, padding, bias=bias)\n",
    "\n",
    "        self.norm = norm\n",
    "        if self.norm == 'batch':\n",
    "            self.bn = torch.nn.BatchNorm2d(output_size)\n",
    "        elif self.norm == 'instance':\n",
    "            self.bn = torch.nn.InstanceNorm2d(output_size)\n",
    "\n",
    "        self.activation = activation\n",
    "        if self.activation == 'relu':\n",
    "            self.act = torch.nn.ReLU(True)\n",
    "        elif self.activation == 'prelu':\n",
    "            self.act = torch.nn.PReLU()\n",
    "        elif self.activation == 'lrelu':\n",
    "            self.act = torch.nn.LeakyReLU(0.2, True)\n",
    "        elif self.activation == 'tanh':\n",
    "            self.act = torch.nn.Tanh()\n",
    "        elif self.activation == 'sigmoid':\n",
    "            self.act = torch.nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.norm is not None:\n",
    "            out = self.bn(self.deconv(x))\n",
    "        else:\n",
    "            out = self.deconv(x)\n",
    "\n",
    "        if self.activation is not None:\n",
    "            return self.act(out)\n",
    "        else:\n",
    "            return out\n",
    "\n",
    "\n",
    "class ResnetBlock(torch.nn.Module):\n",
    "    def __init__(self, num_filter, kernel_size=3, stride=1, padding=1, bias=True, activation='prelu', norm='batch'):\n",
    "        super(ResnetBlock, self).__init__()\n",
    "        self.conv1 = torch.nn.Conv2d(num_filter, num_filter, kernel_size, stride, padding, bias=bias)\n",
    "        self.conv2 = torch.nn.Conv2d(num_filter, num_filter, kernel_size, stride, padding, bias=bias)\n",
    "\n",
    "        self.norm = norm\n",
    "        if self.norm == 'batch':\n",
    "            self.bn = torch.nn.BatchNorm2d(num_filter)\n",
    "        elif norm == 'instance':\n",
    "            self.bn = torch.nn.InstanceNorm2d(num_filter)\n",
    "\n",
    "        self.activation = activation\n",
    "        if self.activation == 'relu':\n",
    "            self.act = torch.nn.ReLU(True)\n",
    "        elif self.activation == 'prelu':\n",
    "            self.act = torch.nn.PReLU()\n",
    "        elif self.activation == 'lrelu':\n",
    "            self.act = torch.nn.LeakyReLU(0.2, True)\n",
    "        elif self.activation == 'tanh':\n",
    "            self.act = torch.nn.Tanh()\n",
    "        elif self.activation == 'sigmoid':\n",
    "            self.act = torch.nn.Sigmoid()\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        if self.norm is not None:\n",
    "            out = self.bn(self.conv1(x))\n",
    "        else:\n",
    "            out = self.conv1(x)\n",
    "\n",
    "        if self.activation is not None:\n",
    "            out = self.act(out)\n",
    "\n",
    "        if self.norm is not None:\n",
    "            out = self.bn(self.conv2(out))\n",
    "        else:\n",
    "            out = self.conv2(out)\n",
    "\n",
    "        out = torch.add(out, residual)\n",
    "        return out\n",
    "\n",
    "class UpBlock(torch.nn.Module):\n",
    "    def __init__(self, num_filter, kernel_size=8, stride=4, padding=2, bias=True, activation='prelu', norm=None):\n",
    "        super(UpBlock, self).__init__()\n",
    "        self.up_conv1 = DeconvBlock(num_filter, num_filter, kernel_size, stride, padding, activation, norm=None)\n",
    "        self.up_conv2 = ConvBlock(num_filter, num_filter, kernel_size, stride, padding, activation, norm=None)\n",
    "        self.up_conv3 = DeconvBlock(num_filter, num_filter, kernel_size, stride, padding, activation, norm=None)        \n",
    "\n",
    "    def forward(self, x):\n",
    "    \th0 = self.up_conv1(x)\n",
    "    \tl0 = self.up_conv2(h0)\n",
    "    \th1 = self.up_conv3(l0 - x)\n",
    "    \treturn h1 + h0\n",
    "\n",
    "class UpBlockPix(torch.nn.Module):\n",
    "    def __init__(self, num_filter, kernel_size=8, stride=4, padding=2, scale=4, bias=True, activation='prelu', norm=None):\n",
    "        super(UpBlockPix, self).__init__()\n",
    "        self.up_conv1 = Upsampler(scale,num_filter)\n",
    "        self.up_conv2 = ConvBlock(num_filter, num_filter, kernel_size, stride, padding, activation, norm=None)\n",
    "        self.up_conv3 = Upsampler(scale,num_filter)        \n",
    "\n",
    "    def forward(self, x):\n",
    "    \th0 = self.up_conv1(x)\n",
    "    \tl0 = self.up_conv2(h0)\n",
    "    \th1 = self.up_conv3(l0 - x)\n",
    "    \treturn h1 + h0\n",
    "        \n",
    "class D_UpBlock(torch.nn.Module):\n",
    "    def __init__(self, num_filter, kernel_size=8, stride=4, padding=2, num_stages=1, bias=True, activation='prelu', norm=None):\n",
    "        super(D_UpBlock, self).__init__()\n",
    "        self.conv = ConvBlock(num_filter*num_stages, num_filter, 1, 1, 0, activation, norm=None)\n",
    "        self.up_conv1 = DeconvBlock(num_filter, num_filter, kernel_size, stride, padding, activation, norm=None)\n",
    "        self.up_conv2 = ConvBlock(num_filter, num_filter, kernel_size, stride, padding, activation, norm=None)\n",
    "        self.up_conv3 = DeconvBlock(num_filter, num_filter, kernel_size, stride, padding, activation, norm=None)        \n",
    "\n",
    "    def forward(self, x):\n",
    "    \tx = self.conv(x)\n",
    "    \th0 = self.up_conv1(x)\n",
    "    \tl0 = self.up_conv2(h0)\n",
    "    \th1 = self.up_conv3(l0 - x)\n",
    "    \treturn h1 + h0\n",
    "\n",
    "class D_UpBlockPix(torch.nn.Module):\n",
    "    def __init__(self, num_filter, kernel_size=8, stride=4, padding=2, num_stages=1, scale=4, bias=True, activation='prelu', norm=None):\n",
    "        super(D_UpBlockPix, self).__init__()\n",
    "        self.conv = ConvBlock(num_filter*num_stages, num_filter, 1, 1, 0, activation, norm=None)\n",
    "        self.up_conv1 = Upsampler(scale,num_filter)\n",
    "        self.up_conv2 = ConvBlock(num_filter, num_filter, kernel_size, stride, padding, activation, norm=None)\n",
    "        self.up_conv3 = Upsampler(scale,num_filter)\n",
    "\n",
    "    def forward(self, x):\n",
    "    \tx = self.conv(x)\n",
    "    \th0 = self.up_conv1(x)\n",
    "    \tl0 = self.up_conv2(h0)\n",
    "    \th1 = self.up_conv3(l0 - x)\n",
    "    \treturn h1 + h0\n",
    "\n",
    "class DownBlock(torch.nn.Module):\n",
    "    def __init__(self, num_filter, kernel_size=8, stride=4, padding=2, bias=True, activation='prelu', norm=None):\n",
    "        super(DownBlock, self).__init__()\n",
    "        self.down_conv1 = ConvBlock(num_filter, num_filter, kernel_size, stride, padding, activation, norm=None)\n",
    "        self.down_conv2 = DeconvBlock(num_filter, num_filter, kernel_size, stride, padding, activation, norm=None)\n",
    "        self.down_conv3 = ConvBlock(num_filter, num_filter, kernel_size, stride, padding, activation, norm=None)\n",
    "\n",
    "    def forward(self, x):\n",
    "    \tl0 = self.down_conv1(x)\n",
    "    \th0 = self.down_conv2(l0)\n",
    "    \tl1 = self.down_conv3(h0 - x)\n",
    "    \treturn l1 + l0\n",
    "\n",
    "class DownBlockPix(torch.nn.Module):\n",
    "    def __init__(self, num_filter, kernel_size=8, stride=4, padding=2, scale=4,bias=True, activation='prelu', norm=None):\n",
    "        super(DownBlockPix, self).__init__()\n",
    "        self.down_conv1 = ConvBlock(num_filter, num_filter, kernel_size, stride, padding, activation, norm=None)\n",
    "        self.down_conv2 = Upsampler(scale,num_filter)\n",
    "        self.down_conv3 = ConvBlock(num_filter, num_filter, kernel_size, stride, padding, activation, norm=None)\n",
    "\n",
    "    def forward(self, x):\n",
    "    \tl0 = self.down_conv1(x)\n",
    "    \th0 = self.down_conv2(l0)\n",
    "    \tl1 = self.down_conv3(h0 - x)\n",
    "    \treturn l1 + l0\n",
    "\n",
    "class D_DownBlock(torch.nn.Module):\n",
    "    def __init__(self, num_filter, kernel_size=8, stride=4, padding=2, num_stages=1, bias=True, activation='prelu', norm=None):\n",
    "        super(D_DownBlock, self).__init__()\n",
    "        self.conv = ConvBlock(num_filter*num_stages, num_filter, 1, 1, 0, activation, norm=None)\n",
    "        self.down_conv1 = ConvBlock(num_filter, num_filter, kernel_size, stride, padding, activation, norm=None)\n",
    "        self.down_conv2 = DeconvBlock(num_filter, num_filter, kernel_size, stride, padding, activation, norm=None)\n",
    "        self.down_conv3 = ConvBlock(num_filter, num_filter, kernel_size, stride, padding, activation, norm=None)\n",
    "\n",
    "    def forward(self, x):\n",
    "    \tx = self.conv(x)\n",
    "    \tl0 = self.down_conv1(x)\n",
    "    \th0 = self.down_conv2(l0)\n",
    "    \tl1 = self.down_conv3(h0 - x)\n",
    "    \treturn l1 + l0\n",
    "\n",
    "class D_DownBlockPix(torch.nn.Module):\n",
    "    def __init__(self, num_filter, kernel_size=8, stride=4, padding=2, num_stages=1, scale=4, bias=True, activation='prelu', norm=None):\n",
    "        super(D_DownBlockPix, self).__init__()\n",
    "        self.conv = ConvBlock(num_filter*num_stages, num_filter, 1, 1, 0, activation, norm=None)\n",
    "        self.down_conv1 = ConvBlock(num_filter, num_filter, kernel_size, stride, padding, activation, norm=None)\n",
    "        self.down_conv2 = Upsampler(scale,num_filter)\n",
    "        self.down_conv3 = ConvBlock(num_filter, num_filter, kernel_size, stride, padding, activation, norm=None)\n",
    "\n",
    "    def forward(self, x):\n",
    "    \tx = self.conv(x)\n",
    "    \tl0 = self.down_conv1(x)\n",
    "    \th0 = self.down_conv2(l0)\n",
    "    \tl1 = self.down_conv3(h0 - x)\n",
    "    \treturn l1 + l0\n",
    "\n",
    "class PSBlock(torch.nn.Module):\n",
    "    def __init__(self, input_size, output_size, scale_factor, kernel_size=3, stride=1, padding=1, bias=True, activation='prelu', norm='batch'):\n",
    "        super(PSBlock, self).__init__()\n",
    "        self.conv = torch.nn.Conv2d(input_size, output_size * scale_factor**2, kernel_size, stride, padding, bias=bias)\n",
    "        self.ps = torch.nn.PixelShuffle(scale_factor)\n",
    "\n",
    "        self.norm = norm\n",
    "        if self.norm == 'batch':\n",
    "            self.bn = torch.nn.BatchNorm2d(output_size)\n",
    "        elif norm == 'instance':\n",
    "            self.bn = torch.nn.InstanceNorm2d(output_size)\n",
    "\n",
    "        self.activation = activation\n",
    "        if self.activation == 'relu':\n",
    "            self.act = torch.nn.ReLU(True)\n",
    "        elif self.activation == 'prelu':\n",
    "            self.act = torch.nn.PReLU()\n",
    "        elif self.activation == 'lrelu':\n",
    "            self.act = torch.nn.LeakyReLU(0.2, True)\n",
    "        elif self.activation == 'tanh':\n",
    "            self.act = torch.nn.Tanh()\n",
    "        elif self.activation == 'sigmoid':\n",
    "            self.act = torch.nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.norm is not None:\n",
    "            out = self.bn(self.ps(self.conv(x)))\n",
    "        else:\n",
    "            out = self.ps(self.conv(x))\n",
    "\n",
    "        if self.activation is not None:\n",
    "            out = self.act(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "class Upsampler(torch.nn.Module):\n",
    "    def __init__(self, scale, n_feat, bn=False, act='prelu', bias=True):\n",
    "        super(Upsampler, self).__init__()\n",
    "        modules = []\n",
    "        for _ in range(int(math.log(scale, 2))):\n",
    "            modules.append(ConvBlock(n_feat, 4 * n_feat, 3, 1, 1, bias, activation=None, norm=None))\n",
    "            modules.append(torch.nn.PixelShuffle(2))\n",
    "            if bn: modules.append(torch.nn.BatchNorm2d(n_feat))\n",
    "            #modules.append(torch.nn.PReLU())\n",
    "        self.up = torch.nn.Sequential(*modules)\n",
    "        \n",
    "        self.activation = act\n",
    "        if self.activation == 'relu':\n",
    "            self.act = torch.nn.ReLU(True)\n",
    "        elif self.activation == 'prelu':\n",
    "            self.act = torch.nn.PReLU()\n",
    "        elif self.activation == 'lrelu':\n",
    "            self.act = torch.nn.LeakyReLU(0.2, True)\n",
    "        elif self.activation == 'tanh':\n",
    "            self.act = torch.nn.Tanh()\n",
    "        elif self.activation == 'sigmoid':\n",
    "            self.act = torch.nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.up(x)\n",
    "        if self.activation is not None:\n",
    "            out = self.act(out)\n",
    "        return out\n",
    "             \n",
    "\n",
    "class Upsample2xBlock(torch.nn.Module):\n",
    "    def __init__(self, input_size, output_size, bias=True, upsample='deconv', activation='relu', norm='batch'):\n",
    "        super(Upsample2xBlock, self).__init__()\n",
    "        scale_factor = 2\n",
    "        # 1. Deconvolution (Transposed convolution)\n",
    "        if upsample == 'deconv':\n",
    "            self.upsample = DeconvBlock(input_size, output_size,\n",
    "                                        kernel_size=4, stride=2, padding=1,\n",
    "                                        bias=bias, activation=activation, norm=norm)\n",
    "\n",
    "        # 2. Sub-pixel convolution (Pixel shuffler)\n",
    "        elif upsample == 'ps':\n",
    "            self.upsample = PSBlock(input_size, output_size, scale_factor=scale_factor,\n",
    "                                    bias=bias, activation=activation, norm=norm)\n",
    "\n",
    "        # 3. Resize and Convolution\n",
    "        elif upsample == 'rnc':\n",
    "            self.upsample = torch.nn.Sequential(\n",
    "                torch.nn.Upsample(scale_factor=scale_factor, mode='nearest'),\n",
    "                ConvBlock(input_size, output_size,\n",
    "                          kernel_size=3, stride=1, padding=1,\n",
    "                          bias=bias, activation=activation, norm=norm)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.upsample(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision.transforms import *\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, num_channels, base_filter, feat, num_stages, scale_factor):\n",
    "        super(Net, self).__init__()\n",
    "        \n",
    "        if scale_factor == 2:\n",
    "        \tkernel = 6\n",
    "        \tstride = 2\n",
    "        \tpadding = 2\n",
    "        elif scale_factor == 4:\n",
    "        \tkernel = 8\n",
    "        \tstride = 4\n",
    "        \tpadding = 2\n",
    "        elif scale_factor == 8:\n",
    "        \tkernel = 12\n",
    "        \tstride = 8\n",
    "        \tpadding = 2\n",
    "        \n",
    "        self.num_stages = num_stages\n",
    "        \n",
    "        #Initial Feature Extraction\n",
    "        self.feat0 = ConvBlock(num_channels, feat, 3, 1, 1, activation='prelu', norm=None)\n",
    "        self.feat1 = ConvBlock(feat, base_filter, 1, 1, 0, activation='prelu', norm=None)\n",
    "        #Back-projection stages\n",
    "        self.up1 = UpBlock(base_filter, kernel, stride, padding)\n",
    "        self.down1 = DownBlock(base_filter, kernel, stride, padding)\n",
    "        self.up2 = UpBlock(base_filter, kernel, stride, padding)\n",
    "        self.down2 = D_DownBlock(base_filter, kernel, stride, padding, 2)\n",
    "        self.up3 = D_UpBlock(base_filter, kernel, stride, padding, 2)\n",
    "        self.down3 = D_DownBlock(base_filter, kernel, stride, padding, 3)\n",
    "        self.up4 = D_UpBlock(base_filter, kernel, stride, padding, 3)\n",
    "        self.down4 = D_DownBlock(base_filter, kernel, stride, padding, 4)\n",
    "        self.up5 = D_UpBlock(base_filter, kernel, stride, padding, 4)\n",
    "        self.down5 = D_DownBlock(base_filter, kernel, stride, padding, 5)\n",
    "        self.up6 = D_UpBlock(base_filter, kernel, stride, padding, 5)\n",
    "        self.down6 = D_DownBlock(base_filter, kernel, stride, padding, 6)\n",
    "        self.up7 = D_UpBlock(base_filter, kernel, stride, padding, 6)\n",
    "        #Reconstruction\n",
    "        self.output_conv = ConvBlock(num_stages*base_filter, num_channels, 3, 1, 1, activation=None, norm=None)\n",
    "        \n",
    "        for m in self.modules():\n",
    "            classname = m.__class__.__name__\n",
    "            if classname.find('Conv2d') != -1:\n",
    "        \t    torch.nn.init.kaiming_normal_(m.weight)\n",
    "        \t    if m.bias is not None:\n",
    "        \t\t    m.bias.data.zero_()\n",
    "            elif classname.find('ConvTranspose2d') != -1:\n",
    "        \t    torch.nn.init.kaiming_normal_(m.weight)\n",
    "        \t    if m.bias is not None:\n",
    "        \t\t    m.bias.data.zero_()\n",
    "            \n",
    "    def forward(self, x):\n",
    "        x = self.feat0(x)\n",
    "        l = self.feat1(x)\n",
    "        \n",
    "        results = []\n",
    "        for i in range(self.num_stages):\n",
    "            h1 = self.up1(l)\n",
    "            l1 = self.down1(h1)\n",
    "            h2 = self.up2(l1)\n",
    "            \n",
    "            concat_h = torch.cat((h2, h1),1)\n",
    "            l = self.down2(concat_h)\n",
    "            \n",
    "            concat_l = torch.cat((l, l1),1)\n",
    "            h = self.up3(concat_l)\n",
    "            \n",
    "            concat_h = torch.cat((h, concat_h),1)\n",
    "            l = self.down3(concat_h)\n",
    "            \n",
    "            concat_l = torch.cat((l, concat_l),1)\n",
    "            h = self.up4(concat_l)\n",
    "            \n",
    "            concat_h = torch.cat((h, concat_h),1)\n",
    "            l = self.down4(concat_h)\n",
    "            \n",
    "            concat_l = torch.cat((l, concat_l),1)\n",
    "            h = self.up5(concat_l)\n",
    "            \n",
    "            concat_h = torch.cat((h, concat_h),1)\n",
    "            l = self.down5(concat_h)\n",
    "            \n",
    "            concat_l = torch.cat((l, concat_l),1)\n",
    "            h = self.up6(concat_l)\n",
    "            \n",
    "            concat_h = torch.cat((h, concat_h),1)\n",
    "            l = self.down6(concat_h)\n",
    "            \n",
    "            concat_l = torch.cat((l, concat_l),1)\n",
    "            h = self.up7(concat_l)\n",
    "            \n",
    "            results.append(h)\n",
    "        \n",
    "        results = torch.cat(results,1)\n",
    "        x = self.output_conv(results)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.utils.data as data\n",
    "import numpy as np\n",
    "from os import listdir\n",
    "from os.path import join\n",
    "from PIL import Image, ImageOps\n",
    "import random\n",
    "from random import randrange\n",
    "\n",
    "def is_image_file(filename):\n",
    "    return any(filename.endswith(extension) for extension in [\".png\", \".jpg\", \".jpeg\"])\n",
    "\n",
    "\n",
    "def load_img(filepath):\n",
    "    img = Image.open(filepath).convert('RGB')\n",
    "    #y, _, _ = img.split()\n",
    "    return img\n",
    "\n",
    "def rescale_img(img_in, scale):\n",
    "    size_in = img_in.size\n",
    "    new_size_in = tuple([int(x * scale) for x in size_in])\n",
    "    img_in = img_in.resize(new_size_in, resample=Image.BICUBIC)\n",
    "    return img_in\n",
    "\n",
    "def get_patch(img_in, img_tar, img_bic, patch_size, scale, ix=-1, iy=-1):\n",
    "    (ih, iw) = img_in.size\n",
    "    (th, tw) = (scale * ih, scale * iw)\n",
    "\n",
    "    patch_mult = scale #if len(scale) > 1 else 1\n",
    "    tp = patch_mult * patch_size\n",
    "    ip = tp // scale\n",
    "\n",
    "    if ix == -1:\n",
    "        ix = random.randrange(0, iw - ip + 1)\n",
    "    if iy == -1:\n",
    "        iy = random.randrange(0, ih - ip + 1)\n",
    "\n",
    "    (tx, ty) = (scale * ix, scale * iy)\n",
    "\n",
    "    img_in = img_in.crop((iy,ix,iy + ip, ix + ip))\n",
    "    img_tar = img_tar.crop((ty,tx,ty + tp, tx + tp))\n",
    "    img_bic = img_bic.crop((ty,tx,ty + tp, tx + tp))\n",
    "                \n",
    "    info_patch = {\n",
    "        'ix': ix, 'iy': iy, 'ip': ip, 'tx': tx, 'ty': ty, 'tp': tp}\n",
    "\n",
    "    return img_in, img_tar, img_bic, info_patch\n",
    "\n",
    "def augment(img_in, img_tar, img_bic, flip_h=True, rot=True):\n",
    "    info_aug = {'flip_h': False, 'flip_v': False, 'trans': False}\n",
    "    \n",
    "    if random.random() < 0.5 and flip_h:\n",
    "        img_in = ImageOps.flip(img_in)\n",
    "        img_tar = ImageOps.flip(img_tar)\n",
    "        img_bic = ImageOps.flip(img_bic)\n",
    "        info_aug['flip_h'] = True\n",
    "\n",
    "    if rot:\n",
    "        if random.random() < 0.5:\n",
    "            img_in = ImageOps.mirror(img_in)\n",
    "            img_tar = ImageOps.mirror(img_tar)\n",
    "            img_bic = ImageOps.mirror(img_bic)\n",
    "            info_aug['flip_v'] = True\n",
    "        if random.random() < 0.5:\n",
    "            img_in = img_in.rotate(180)\n",
    "            img_tar = img_tar.rotate(180)\n",
    "            img_bic = img_bic.rotate(180)\n",
    "            info_aug['trans'] = True\n",
    "            \n",
    "    return img_in, img_tar, img_bic, info_aug\n",
    "    \n",
    "class DatasetFromFolder(data.Dataset):\n",
    "    def __init__(self, image_dir, patch_size, upscale_factor, data_augmentation, transform=None):\n",
    "        super(DatasetFromFolder, self).__init__()\n",
    "        self.image_filenames = [join(image_dir, x) for x in listdir(image_dir) if is_image_file(x)]\n",
    "        self.patch_size = patch_size\n",
    "        self.upscale_factor = upscale_factor\n",
    "        self.transform = transform\n",
    "        self.data_augmentation = data_augmentation\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        target = load_img(self.image_filenames[index])\n",
    "        \n",
    "        input = target.resize((int(target.size[0]/self.upscale_factor),int(target.size[1]/self.upscale_factor)), Image.BICUBIC)       \n",
    "        bicubic = rescale_img(input, self.upscale_factor)\n",
    "        \n",
    "        input, target, bicubic, _ = get_patch(input,target,bicubic,self.patch_size, self.upscale_factor)\n",
    "        \n",
    "        if self.data_augmentation:\n",
    "            input, target, bicubic, _ = augment(input, target, bicubic)\n",
    "        \n",
    "        if self.transform:\n",
    "            input = self.transform(input)\n",
    "            bicubic = self.transform(bicubic)\n",
    "            target = self.transform(target)\n",
    "                \n",
    "        return input, target, bicubic\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_filenames)\n",
    "\n",
    "class DatasetFromFolderEval(data.Dataset):\n",
    "    def __init__(self, lr_dir, upscale_factor, transform=None):\n",
    "        super(DatasetFromFolderEval, self).__init__()\n",
    "        self.image_filenames = [join(lr_dir, x) for x in listdir(lr_dir) if is_image_file(x)]\n",
    "        self.upscale_factor = upscale_factor\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        input = load_img(self.image_filenames[index])\n",
    "        _, file = os.path.split(self.image_filenames[index])\n",
    "\n",
    "        bicubic = rescale_img(input, self.upscale_factor)\n",
    "        \n",
    "        if self.transform:\n",
    "            input = self.transform(input)\n",
    "            bicubic = self.transform(bicubic)\n",
    "            \n",
    "        return input, bicubic, file\n",
    "      \n",
    "    def __len__(self):\n",
    "        return len(self.image_filenames)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os.path import join\n",
    "from torchvision.transforms import Compose, ToTensor\n",
    "\n",
    "\n",
    "def transform():\n",
    "    return Compose([\n",
    "        ToTensor(),\n",
    "    ])\n",
    "\n",
    "def get_training_set(data_dir, hr, upscale_factor, patch_size, data_augmentation):\n",
    "    hr_dir = join(data_dir, hr)\n",
    "    return DatasetFromFolder(hr_dir,patch_size, upscale_factor, data_augmentation,\n",
    "                             transform=transform())\n",
    "\n",
    "def get_eval_set(lr_dir, upscale_factor):\n",
    "    return DatasetFromFolderEval(lr_dir, upscale_factor,\n",
    "                             transform=transform())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [--upscale_factor UPSCALE_FACTOR] [--batchSize BATCHSIZE] [--nEpochs NEPOCHS] [--snapshots SNAPSHOTS] [--start_iter START_ITER]\n",
      "                             [--lr LR] [--gpu_mode GPU_MODE] [--threads THREADS] [--seed SEED] [--gpus GPUS] [--data_dir DATA_DIR]\n",
      "                             [--data_augmentation DATA_AUGMENTATION] [--hr_train_dataset HR_TRAIN_DATASET] [--model_type MODEL_TYPE] [--residual RESIDUAL]\n",
      "                             [--patch_size PATCH_SIZE] [--pretrained_sr PRETRAINED_SR] [--pretrained PRETRAINED] [--save_folder SAVE_FOLDER] [--prefix PREFIX]\n",
      "ipykernel_launcher.py: error: unrecognized arguments: -f /Users/prakanshulsaxena/Library/Jupyter/runtime/kernel-1fed84e0-4723-4554-9531-090b61f83905.json\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/prakanshulsaxena/opt/anaconda3/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3426: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import argparse\n",
    "from math import log10\n",
    "\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "import pdb\n",
    "import socket\n",
    "import time\n",
    "\n",
    "# Training settings\n",
    "parser = argparse.ArgumentParser(description='PyTorch Super Res Example')\n",
    "# parser.add_argument('--upscale_factor', type=int, default=8, help=\"super resolution upscale factor\")\n",
    "# parser.add_argument('--batchSize', type=int, default=1, help='training batch size')\n",
    "# parser.add_argument('--nEpochs', type=int, default=2000, help='number of epochs to train for')\n",
    "# parser.add_argument('--snapshots', type=int, default=50, help='Snapshots')\n",
    "# parser.add_argument('--start_iter', type=int, default=1, help='Starting Epoch')\n",
    "# parser.add_argument('--lr', type=float, default=1e-4, help='Learning Rate. Default=0.01')\n",
    "parser.add_argument('--gpu_mode', type=bool, default=True)\n",
    "# parser.add_argument('--threads', type=int, default=1, help='number of threads for data loader to use')\n",
    "# parser.add_argument('--seed', type=int, default=123, help='random seed to use. Default=123')\n",
    "parser.add_argument('--gpus', default=1, type=int, help='number of gpu')\n",
    "parser.add_argument('--data_dir', type=str, default='./Dataset')\n",
    "parser.add_argument('--data_augmentation', type=bool, default=True)\n",
    "parser.add_argument('--hr_train_dataset', type=str, default='DIV2K_train_HR')\n",
    "# parser.add_argument('--model_type', type=str, default='DBPNLL')\n",
    "parser.add_argument('--residual', type=bool, default=True)\n",
    "# parser.add_argument('--patch_size', type=int, default=40, help='Size of cropped HR image')\n",
    "# parser.add_argument('--pretrained_sr', default='MIX2K_LR_aug_x4dl10DBPNITERtpami_epoch_399.pth', help='sr pretrained base model')\n",
    "parser.add_argument('--pretrained', type=bool, default=False)\n",
    "parser.add_argument('--save_folder', default='weights/', help='Location to save checkpoint models')\n",
    "parser.add_argument('--prefix', default='tpami_residual_filter8', help='Location to save checkpoint models')\n",
    "\n",
    "upscale_factor = 8\n",
    "batchSize = 1\n",
    "nEpochs = 2000\n",
    "snapshots = 50\n",
    "start_iter = 1\n",
    "threads = 1\n",
    "seed = 123\n",
    "lr = .01\n",
    "patch_size = 40\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "opt = parser.parse_args()\n",
    "gpus_list = range(opt.gpus)\n",
    "hostname = str(socket.gethostname())\n",
    "cudnn.benchmark = True\n",
    "print(opt)\n",
    "\n",
    "def train(epoch):\n",
    "    epoch_loss = 0\n",
    "    model.train()\n",
    "    for iteration, batch in enumerate(training_data_loader, 1):\n",
    "        input, target, bicubic = Variable(batch[0]), Variable(batch[1]), Variable(batch[2])\n",
    "        if cuda:\n",
    "            input = input.cuda(gpus_list[0])\n",
    "            target = target.cuda(gpus_list[0])\n",
    "            bicubic = bicubic.cuda(gpus_list[0])\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        t0 = time.time()\n",
    "        prediction = model(input)\n",
    "\n",
    "        if TRUE:\n",
    "            prediction = prediction + bicubic\n",
    "\n",
    "        loss = criterion(prediction, target)\n",
    "        t1 = time.time()\n",
    "        epoch_loss += loss.data\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        print(\"===> Epoch[{}]({}/{}): Loss: {:.4f} || Timer: {:.4f} sec.\".format(epoch, iteration, len(training_data_loader), loss.data, (t1 - t0)))\n",
    "\n",
    "    print(\"===> Epoch {} Complete: Avg. Loss: {:.4f}\".format(epoch, epoch_loss / len(training_data_loader)))\n",
    "\n",
    "\n",
    "def test():\n",
    "    avg_psnr = 0\n",
    "    for batch in testing_data_loader:\n",
    "        input, target = Variable(batch[0]), Variable(batch[1])\n",
    "        if cuda:\n",
    "            input = input.cuda(gpus_list[0])\n",
    "            target = target.cuda(gpus_list[0])\n",
    "\n",
    "        prediction = model(input)\n",
    "        mse = criterion(prediction, target)\n",
    "        psnr = 10 * log10(1 / mse.data[0])\n",
    "        avg_psnr += psnr\n",
    "    print(\"===> Avg. PSNR: {:.4f} dB\".format(avg_psnr / len(testing_data_loader)))\n",
    "\n",
    "def print_network(net):\n",
    "    num_params = 0\n",
    "    for param in net.parameters():\n",
    "        num_params += param.numel()\n",
    "    print(net)\n",
    "    print('Total number of parameters: %d' % num_params)\n",
    "\n",
    "def checkpoint(epoch):\n",
    "    model_out_path = opt.save_folder+opt.train_dataset+hostname+opt.model_type+opt.prefix+\"_epoch_{}.pth\".format(epoch)\n",
    "    torch.save(model.state_dict(), model_out_path)\n",
    "    print(\"Checkpoint saved to {}\".format(model_out_path))\n",
    "\n",
    "cuda = opt.gpu_mode\n",
    "if cuda and not torch.cuda.is_available():\n",
    "    raise Exception(\"No GPU found, please run without --cuda\")\n",
    "\n",
    "torch.manual_seed(opt.seed)  #torch.manual_seed(123)\n",
    "if cuda:\n",
    "    torch.cuda.manual_seed(opt.seed)  #torch.manual_seed(123)\n",
    "\n",
    "print('===> Loading datasets')\n",
    "train_set = get_training_set(opt.data_dir, opt.hr_train_dataset, opt.upscale_factor, opt.patch_size, opt.data_augmentation)\n",
    "#train_set = get_training_set(data_dir = ''./Dataset', hr_train_dataset = DIV2k_train_HR, upscale_factor=9, patch_size = 40, data_augmentation=TRUE)\n",
    "\n",
    "training_data_loader = DataLoader(dataset=train_set, num_workers=opt.threads, batch_size=opt.batchSize, shuffle=True)\n",
    "#training_data_loader = DataLoader(dataset=train_set, num_workers_threads=1 , batch_size=1, shuffle=True)\n",
    "\n",
    "print('===> Building model ', opt.model_type)\n",
    "if opt.model_type == 'DBPNLL':\n",
    "    model = DBPNLL(num_channels=3, base_filter=64,  feat = 256, num_stages=10, scale_factor=opt.upscale_factor) \n",
    "elif opt.model_type == 'DBPN-RES-MR64-3':\n",
    "    model = DBPNITER(num_channels=3, base_filter=64,  feat = 256, num_stages=3, scale_factor=opt.upscale_factor)\n",
    "else:\n",
    "    model = DBPN(num_channels=3, base_filter=64,  feat = 256, num_stages=7, scale_factor=opt.upscale_factor) \n",
    "    \n",
    "model = torch.nn.DataParallel(model, device_ids=gpus_list)\n",
    "criterion = nn.L1Loss()\n",
    "\n",
    "print('---------- Networks architecture -------------')\n",
    "print_network(model)\n",
    "print('----------------------------------------------')\n",
    "\n",
    "# if opt.pretrained:\n",
    "#     model_name = os.path.join(opt.save_folder + opt.pretrained_sr)\n",
    "#     if os.path.exists(model_name):\n",
    "#         #model= torch.load(model_name, map_location=lambda storage, loc: storage)\n",
    "#         model.load_state_dict(torch.load(model_name, map_location=lambda storage, loc: storage))\n",
    "#         print('Pre-trained SR model is loaded.')\n",
    "\n",
    "if cuda:\n",
    "    model = model.cuda(gpus_list[0])\n",
    "    criterion = criterion.cuda(gpus_list[0])\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=opt.lr, betas=(0.9, 0.999), eps=1e-8)\n",
    "#optimizer = optim.Adam(model.parameters(), lr=learning rate, betas=(0.9, 0.999), eps=1e-8)\n",
    "\n",
    "for epoch in range(opt.start_iter, opt.nEpochs + 1):\n",
    "#for epoch in range(1, 2000 + 1):\n",
    "    train(epoch)\n",
    "\n",
    "    # learning rate is decayed by a factor of 10 every half of total epochs\n",
    "    if (epoch+1) % (opt.nEpochs/2) == 0:\n",
    "        #if (epoch+1) % (2000/2) == 0:\n",
    "        \n",
    "        for param_group in optimizer.param_groups:\n",
    "            param_group['lr'] /= 10.0\n",
    "        print('Learning rate decay: lr={}'.format(optimizer.param_groups[0]['lr']))\n",
    "            \n",
    "    if (epoch+1) % (opt.snapshots) == 0:\n",
    "        #if (epoch+1) % (50) == 0:\n",
    "        checkpoint(epoch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mSystemExit\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-d020dc0fc557>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_argument\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'--prefix'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'tpami_residual_filter8'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhelp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Location to save checkpoint models'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m \u001b[0mopt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0mgpus_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgpus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0mhostname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgethostname\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/argparse.py\u001b[0m in \u001b[0;36mparse_args\u001b[0;34m(self, args, namespace)\u001b[0m\n\u001b[1;32m   1769\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0margv\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1770\u001b[0m             \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'unrecognized arguments: %s'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1771\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m' '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1772\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1773\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/argparse.py\u001b[0m in \u001b[0;36merror\u001b[0;34m(self, message)\u001b[0m\n\u001b[1;32m   2519\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_usage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_sys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstderr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2520\u001b[0m         \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'prog'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprog\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'message'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2521\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'%(prog)s: error: %(message)s\\n'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/argparse.py\u001b[0m in \u001b[0;36mexit\u001b[0;34m(self, status, message)\u001b[0m\n\u001b[1;32m   2506\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2507\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_print_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_sys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstderr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2508\u001b[0;31m         \u001b[0m_sys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2509\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2510\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mSystemExit\u001b[0m: 2"
     ]
    }
   ],
   "source": [
    "%tb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import argparse\n",
    "\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "from dbpn import Net as DBPN\n",
    "from dbpn_v1 import Net as DBPNLL\n",
    "from dbpn_iterative import Net as DBPNITER\n",
    "from data import get_eval_set\n",
    "from functools import reduce\n",
    "\n",
    "from scipy.misc import imsave\n",
    "import scipy.io as sio\n",
    "import time\n",
    "import cv2\n",
    "\n",
    "# Training settings\n",
    "parser = argparse.ArgumentParser(description='PyTorch Super Res Example')\n",
    "# parser.add_argument('--upscale_factor', type=int, default=8, help=\"super resolution upscale factor\")\n",
    "# parser.add_argument('--testBatchSize', type=int, default=1, help='testing batch size')\n",
    "parser.add_argument('--gpu_mode', type=bool, default=True)\n",
    "parser.add_argument('--self_ensemble', type=bool, default=False)\n",
    "parser.add_argument('--chop_forward', type=bool, default=False)\n",
    "# parser.add_argument('--threads', type=int, default=1, help='number of threads for data loader to use')\n",
    "# parser.add_argument('--seed', type=int, default=123, help='random seed to use. Default=123')\n",
    "parser.add_argument('--gpus', default=1, type=int, help='number of gpu')\n",
    "parser.add_argument('--input_dir', type=str, default='Input')\n",
    "parser.add_argument('--output', default='Results/', help='Location to save checkpoint models')\n",
    "parser.add_argument('--test_dataset', type=str, default='Set5_LR_x8')\n",
    "# parser.add_argument('--model_type', type=str, default='DBPNLL')\n",
    "parser.add_argument('--residual', type=bool, default=False)\n",
    "# parser.add_argument('--model', default='models/DBPNLL_x8.pth', help='sr pretrained base model')\n",
    "\n",
    "\n",
    "testBatchSize = 1\n",
    "threads = 1\n",
    "seed = 123\n",
    "\n",
    "opt = parser.parse_args()\n",
    "\n",
    "gpus_list=range(opt.gpus)\n",
    "print(opt)\n",
    "\n",
    "cuda = opt.gpu_mode\n",
    "if cuda and not torch.cuda.is_available():\n",
    "    raise Exception(\"No GPU found, please run without --cuda\")\n",
    "\n",
    "torch.manual_seed(opt.seed)\n",
    "#torch.manual_seed(123)\n",
    "if cuda:\n",
    "    torch.cuda.manual_seed(opt.seed)\n",
    "    #torch.cuda.manual_seed(123)\n",
    "    \n",
    "\n",
    "print('===> Loading datasets')\n",
    "test_set = get_eval_set(os.path.join(opt.input_dir,opt.test_dataset), opt.upscale_factor)\n",
    "#test_set = get_eval_set(os.path.join(input directory,SET5 file), 8)\n",
    "testing_data_loader = DataLoader(dataset=test_set, num_workers=opt.threads, batch_size=opt.testBatchSize, shuffle=False)\n",
    "#testing_data_loader = DataLoader(dataset=test_set, num_workers=1, batch_size=1, shuffle=False)\n",
    "\n",
    "print('===> Building model')\n",
    "if opt.model_type == 'DBPNLL':\n",
    "    model = DBPNLL(num_channels=3, base_filter=64,  feat = 256, num_stages=10, scale_factor=opt.upscale_factor) ###D-DBPN\n",
    "    #model = DBPNLL(num_channels=3, base_filter=64,  feat = 256, num_stages=10, scale_factor=8)\n",
    "elif opt.model_type == 'DBPN-RES-MR64-3':\n",
    "    model = DBPNITER(num_channels=3, base_filter=64,  feat = 256, num_stages=3, scale_factor=opt.upscale_factor) ###D-DBPN\n",
    "    #model = DBPNITER(num_channels=3, base_filter=64,  feat = 256, num_stages=3, scale_factor=1)\n",
    "else:\n",
    "    model = DBPN(num_channels=3, base_filter=64,  feat = 256, num_stages=7, scale_factor=opt.upscale_factor) ###D-DBPN\n",
    "    #model = DBPN(num_channels=3, base_filter=64,  feat = 256, num_stages=7, scale_factor=1)\n",
    "    \n",
    "if cuda:\n",
    "    model = torch.nn.DataParallel(model, device_ids=gpus_list)\n",
    "\n",
    "model.load_state_dict(torch.load(opt.model, map_location=lambda storage, loc: storage))\n",
    "#model.load_state_dict(torch.load(location of the trained model, map_location=lambda storage, loc: storage))\n",
    "print('Pre-trained SR model is loaded.')\n",
    "\n",
    "if cuda:\n",
    "    model = model.cuda(gpus_list[0])\n",
    "\n",
    "def eval():\n",
    "    model.eval()\n",
    "    for batch in testing_data_loader:\n",
    "        with torch.no_grad():\n",
    "            input, bicubic, name = Variable(batch[0]), Variable(batch[1]), batch[2]\n",
    "        if cuda:\n",
    "            input = input.cuda(gpus_list[0])\n",
    "            bicubic = bicubic.cuda(gpus_list[0])\n",
    "\n",
    "        t0 = time.time()\n",
    "        if opt.chop_forward:\n",
    "            with torch.no_grad():\n",
    "                prediction = chop_forward(input, model, opt.upscale_factor)\n",
    "                #prediction = chop_forward(input, model, 8)\n",
    "        else:\n",
    "            if opt.self_ensemble:\n",
    "                with torch.no_grad():\n",
    "                    prediction = x8_forward(input, model)\n",
    "            else:\n",
    "                with torch.no_grad():\n",
    "                    prediction = model(input)\n",
    "                \n",
    "        if opt.residual:\n",
    "            #if TRUE:\n",
    "            prediction = prediction + bicubic\n",
    "\n",
    "        t1 = time.time()\n",
    "        print(\"===> Processing: %s || Timer: %.4f sec.\" % (name[0], (t1 - t0)))\n",
    "        save_img(prediction.cpu().data, name[0])\n",
    "\n",
    "def save_img(img, img_name):\n",
    "    save_img = img.squeeze().clamp(0, 1).numpy().transpose(1,2,0)\n",
    "    # save img\n",
    "    save_dir=os.path.join(opt.output,opt.test_dataset)\n",
    "    #save_dir=os.path.join(ouput result save location,test dataset)\n",
    "    if not os.path.exists(save_dir):\n",
    "        os.makedirs(save_dir)\n",
    "        \n",
    "    save_fn = save_dir +'/'+ img_name\n",
    "    cv2.imwrite(save_fn, cv2.cvtColor(save_img*255, cv2.COLOR_BGR2RGB),  [cv2.IMWRITE_PNG_COMPRESSION, 0])\n",
    "\n",
    "def x8_forward(img, model, precision='single'):\n",
    "    def _transform(v, op):\n",
    "        if precision != 'single': v = v.float()\n",
    "\n",
    "        v2np = v.data.cpu().numpy()\n",
    "        if op == 'vflip':\n",
    "            tfnp = v2np[:, :, :, ::-1].copy()\n",
    "        elif op == 'hflip':\n",
    "            tfnp = v2np[:, :, ::-1, :].copy()\n",
    "        elif op == 'transpose':\n",
    "            tfnp = v2np.transpose((0, 1, 3, 2)).copy()\n",
    "        \n",
    "        ret = torch.Tensor(tfnp).cuda()\n",
    "\n",
    "        if precision == 'half':\n",
    "            ret = ret.half()\n",
    "        elif precision == 'double':\n",
    "            ret = ret.double()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            ret = Variable(ret)\n",
    "\n",
    "        return ret\n",
    "\n",
    "    inputlist = [img]\n",
    "    for tf in 'vflip', 'hflip', 'transpose':\n",
    "        inputlist.extend([_transform(t, tf) for t in inputlist])\n",
    "\n",
    "    outputlist = [model(aug) for aug in inputlist]\n",
    "    for i in range(len(outputlist)):\n",
    "        if i > 3:\n",
    "            outputlist[i] = _transform(outputlist[i], 'transpose')\n",
    "        if i % 4 > 1:\n",
    "            outputlist[i] = _transform(outputlist[i], 'hflip')\n",
    "        if (i % 4) % 2 == 1:\n",
    "            outputlist[i] = _transform(outputlist[i], 'vflip')\n",
    "    \n",
    "    output = reduce((lambda x, y: x + y), outputlist) / len(outputlist)\n",
    "\n",
    "    return output\n",
    "    \n",
    "def chop_forward(x, model, scale, shave=8, min_size=80000, nGPUs=opt.gpus):\n",
    "    b, c, h, w = x.size()\n",
    "    h_half, w_half = h // 2, w // 2\n",
    "    h_size, w_size = h_half + shave, w_half + shave\n",
    "    inputlist = [\n",
    "        x[:, :, 0:h_size, 0:w_size],\n",
    "        x[:, :, 0:h_size, (w - w_size):w],\n",
    "        x[:, :, (h - h_size):h, 0:w_size],\n",
    "        x[:, :, (h - h_size):h, (w - w_size):w]]\n",
    "\n",
    "    if w_size * h_size < min_size:\n",
    "        outputlist = []\n",
    "        for i in range(0, 4, nGPUs):\n",
    "            with torch.no_grad():\n",
    "                input_batch = torch.cat(inputlist[i:(i + nGPUs)], dim=0)\n",
    "            if opt.self_ensemble:\n",
    "                #if FALSE:\n",
    "                with torch.no_grad():\n",
    "                    output_batch = x8_forward(input_batch, model)\n",
    "            else:\n",
    "                with torch.no_grad():\n",
    "                    output_batch = model(input_batch)\n",
    "            outputlist.extend(output_batch.chunk(nGPUs, dim=0))\n",
    "    else:\n",
    "        outputlist = [\n",
    "            chop_forward(patch, model, scale, shave, min_size, nGPUs) \\\n",
    "            for patch in inputlist]\n",
    "\n",
    "    h, w = scale * h, scale * w\n",
    "    h_half, w_half = scale * h_half, scale * w_half\n",
    "    h_size, w_size = scale * h_size, scale * w_size\n",
    "    shave *= scale\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = Variable(x.data.new(b, c, h, w))\n",
    "\n",
    "    output[:, :, 0:h_half, 0:w_half] \\\n",
    "        = outputlist[0][:, :, 0:h_half, 0:w_half]\n",
    "    output[:, :, 0:h_half, w_half:w] \\\n",
    "        = outputlist[1][:, :, 0:h_half, (w_size - w + w_half):w_size]\n",
    "    output[:, :, h_half:h, 0:w_half] \\\n",
    "        = outputlist[2][:, :, (h_size - h + h_half):h_size, 0:w_half]\n",
    "    output[:, :, h_half:h, w_half:w] \\\n",
    "        = outputlist[3][:, :, (h_size - h + h_half):h_size, (w_size - w + w_half):w_size]\n",
    "\n",
    "    return output\n",
    "\n",
    "##Eval Start!!!!\n",
    "eval()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
