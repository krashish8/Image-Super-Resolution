{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"BTP - EDSR.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyP+Zq6gkqjdiQVW1mmzrf07"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"K4Ei0p-l8mIA","executionInfo":{"status":"ok","timestamp":1620036643451,"user_tz":-330,"elapsed":38067,"user":{"displayName":"ASHISH KUMAR 4-Yr B.Tech. Comp. Sci. and Engg, 2018-2022","photoUrl":"","userId":"09157645467553063630"}},"outputId":"be0cee92-77e0-4724-bfed-c97d08f7bc11"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"zQZt4x2o89zm","executionInfo":{"status":"ok","timestamp":1620036649056,"user_tz":-330,"elapsed":3888,"user":{"displayName":"ASHISH KUMAR 4-Yr B.Tech. Comp. Sci. and Engg, 2018-2022","photoUrl":"","userId":"09157645467553063630"}}},"source":["import torch.utils.data as data\n","import torch\n","import h5py\n","\n","class DatasetFromHdf5(data.Dataset):\n","    def __init__(self, file_path):\n","        super(DatasetFromHdf5, self).__init__()\n","        hf = h5py.File(file_path)\n","        self.data = hf.get('data')\n","        self.target = hf.get('label')\n","\n","    def __getitem__(self, index):\n","        return torch.from_numpy(self.data[index,:,:,:]).float(), torch.from_numpy(self.target[index,:,:,:]).float()\n","\n","    def __len__(self):\n","        return self.data.shape[0]"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"nq5D4Z4m9BJT","executionInfo":{"status":"ok","timestamp":1620036649058,"user_tz":-330,"elapsed":3876,"user":{"displayName":"ASHISH KUMAR 4-Yr B.Tech. Comp. Sci. and Engg, 2018-2022","photoUrl":"","userId":"09157645467553063630"}}},"source":["import torch\n","import torch.nn as nn\n","import math\n","\n","class MeanShift(nn.Conv2d):\n","    def __init__(self, rgb_mean, sign):\n","        super(MeanShift, self).__init__(3, 3, kernel_size=1)\n","        self.weight.data = torch.eye(3).view(3, 3, 1, 1)\n","        self.bias.data = float(sign) * torch.Tensor(rgb_mean)\n","\n","        # Freeze the MeanShift layer\n","        for params in self.parameters():\n","            params.requires_grad = False\n","\n","class _Residual_Block(nn.Module): \n","    def __init__(self):\n","        super(_Residual_Block, self).__init__()\n","\n","        self.conv1 = nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, stride=1, padding=1, bias=False)\n","        self.relu = nn.ReLU(inplace=True)\n","        self.conv2 = nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, stride=1, padding=1, bias=False)\n","\n","    def forward(self, x): \n","        identity_data = x\n","        output = self.relu(self.conv1(x))\n","        output = self.conv2(output)\n","        output *= 0.1\n","        output = torch.add(output,identity_data)\n","        return output \n","\n","class EDSR(nn.Module):\n","    def __init__(self):\n","        super(EDSR, self).__init__()\n","\n","        rgb_mean = (0.4488, 0.4371, 0.4040)\n","        self.sub_mean = MeanShift(rgb_mean, -1)\n","\n","        self.conv_input = nn.Conv2d(in_channels=3, out_channels=256, kernel_size=3, stride=1, padding=1, bias=False)\n","\n","        self.residual = self.make_layer(_Residual_Block, 32)\n","\n","        self.conv_mid = nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, stride=1, padding=1, bias=False)\n","\n","        self.upscale4x = nn.Sequential(\n","            nn.Conv2d(in_channels=256, out_channels=256*4, kernel_size=3, stride=1, padding=1, bias=False),\n","            nn.PixelShuffle(2),\n","            nn.Conv2d(in_channels=256, out_channels=256*4, kernel_size=3, stride=1, padding=1, bias=False),\n","            nn.PixelShuffle(2),\n","        )\n","\n","        self.conv_output = nn.Conv2d(in_channels=256, out_channels=3, kernel_size=3, stride=1, padding=1, bias=False)\n","\n","        self.add_mean = MeanShift(rgb_mean, 1)\n","\n","        for m in self.modules():\n","            if isinstance(m, nn.Conv2d):\n","                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n","                m.weight.data.normal_(0, math.sqrt(2. / n))\n","                if m.bias is not None:\n","                    m.bias.data.zero_()\n","            elif isinstance(m, nn.BatchNorm2d):\n","                m.weight.data.fill_(1)\n","                if m.bias is not None:\n","                    m.bias.data.zero_()\n","\n","    def make_layer(self, block, num_of_layer):\n","        layers = []\n","        for _ in range(num_of_layer):\n","            layers.append(block())\n","        return nn.Sequential(*layers)\n","\n","    def forward(self, x):\n","        out = self.sub_mean(x)\n","        out = self.conv_input(out)\n","        residual = out\n","        out = self.conv_mid(self.residual(out))\n","        out = torch.add(out,residual)\n","        out = self.upscale4x(out)\n","        out = self.conv_output(out)\n","        out = self.add_mean(out)\n","        return out"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"vea_10y19D2b","executionInfo":{"status":"ok","timestamp":1620036649600,"user_tz":-330,"elapsed":4412,"user":{"displayName":"ASHISH KUMAR 4-Yr B.Tech. Comp. Sci. and Engg, 2018-2022","photoUrl":"","userId":"09157645467553063630"}}},"source":["import torch\n","import numpy as np\n","from scipy.ndimage import gaussian_filter\n","\n","\n","def calc_patch_size(func):\n","    def wrapper(args):\n","        if scale == 2:\n","            patch_size = 10\n","        elif scale == 3:\n","            patch_size = 7\n","        elif scale == 4:\n","            patch_size = 6\n","        else:\n","            raise Exception('Scale Error', scale)\n","        return func(args)\n","    return wrapper\n","\n","\n","def convert_rgb_to_y(img, dim_order='hwc'):\n","    if dim_order == 'hwc':\n","        return 16. + (64.738 * img[..., 0] + 129.057 * img[..., 1] + 25.064 * img[..., 2]) / 256.\n","    else:\n","        return 16. + (64.738 * img[0] + 129.057 * img[1] + 25.064 * img[2]) / 256.\n","\n","\n","def convert_rgb_to_ycbcr(img, dim_order='hwc'):\n","    if dim_order == 'hwc':\n","        y = 16. + (64.738 * img[..., 0] + 129.057 * img[..., 1] + 25.064 * img[..., 2]) / 256.\n","        cb = 128. + (-37.945 * img[..., 0] - 74.494 * img[..., 1] + 112.439 * img[..., 2]) / 256.\n","        cr = 128. + (112.439 * img[..., 0] - 94.154 * img[..., 1] - 18.285 * img[..., 2]) / 256.\n","    else:\n","        y = 16. + (64.738 * img[0] + 129.057 * img[1] + 25.064 * img[2]) / 256.\n","        cb = 128. + (-37.945 * img[0] - 74.494 * img[1] + 112.439 * img[2]) / 256.\n","        cr = 128. + (112.439 * img[0] - 94.154 * img[1] - 18.285 * img[2]) / 256.\n","    return np.array([y, cb, cr]).transpose([1, 2, 0])\n","\n","\n","def convert_ycbcr_to_rgb(img, dim_order='hwc'):\n","    if dim_order == 'hwc':\n","        r = 298.082 * img[..., 0] / 256. + 408.583 * img[..., 2] / 256. - 222.921\n","        g = 298.082 * img[..., 0] / 256. - 100.291 * img[..., 1] / 256. - 208.120 * img[..., 2] / 256. + 135.576\n","        b = 298.082 * img[..., 0] / 256. + 516.412 * img[..., 1] / 256. - 276.836\n","    else:\n","        r = 298.082 * img[0] / 256. + 408.583 * img[2] / 256. - 222.921\n","        g = 298.082 * img[0] / 256. - 100.291 * img[1] / 256. - 208.120 * img[2] / 256. + 135.576\n","        b = 298.082 * img[0] / 256. + 516.412 * img[1] / 256. - 276.836\n","    return np.array([r, g, b]).transpose([1, 2, 0])\n","\n","\n","def preprocess(img, device):\n","    img = np.array(img).astype(np.float32)\n","    ycbcr = convert_rgb_to_ycbcr(img)\n","    x = ycbcr[..., 0]\n","    x /= 255.\n","    x = torch.from_numpy(x).to(device)\n","    x = x.unsqueeze(0).unsqueeze(0)\n","    return x, ycbcr\n","\n","\n","def calc_psnr(img1, img2):\n","    return 10. * torch.log10(1. / torch.mean((img1 - img2) ** 2))\n","\n","\n","def calc_ssim(img1, img2, sd=1.5, C1=0.01**2, C2=0.03**2):\n","    img1 = img1.cpu()\n","    img2 = img2.cpu()\n","    mu1 = gaussian_filter(img1, sd)\n","    mu2 = gaussian_filter(img2, sd)\n","    mu1_sq = mu1 * mu1\n","    mu2_sq = mu2 * mu2\n","    mu1_mu2 = mu1 * mu2\n","    sigma1_sq = gaussian_filter(img1 * img1, sd) - mu1_sq\n","    sigma2_sq = gaussian_filter(img2 * img2, sd) - mu2_sq\n","    sigma12 = gaussian_filter(img1 * img2, sd) - mu1_mu2\n","    \n","    ssim_num = ((2 * mu1_mu2 + C1) * (2 * sigma12 + C2))\n","    ssim_den = ((mu1_sq + mu2_sq + C1) * (sigma1_sq + sigma2_sq + C2))\n","    ssim_map = ssim_num / ssim_den\n","    mssim = np.mean(ssim_map)\n","    \n","    return mssim\n","\n","\n","class AverageMeter(object):\n","    def __init__(self):\n","        self.reset()\n","\n","    def reset(self):\n","        self.val = 0\n","        self.avg = 0\n","        self.sum = 0\n","        self.count = 0\n","\n","    def update(self, val, n=1):\n","        self.val = val\n","        self.sum += val * n\n","        self.count += n\n","        self.avg = self.sum / self.count"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"3Dy7hj989Fv-","executionInfo":{"status":"ok","timestamp":1620036649601,"user_tz":-330,"elapsed":4408,"user":{"displayName":"ASHISH KUMAR 4-Yr B.Tech. Comp. Sci. and Engg, 2018-2022","photoUrl":"","userId":"09157645467553063630"}}},"source":["import os\n","import torch\n","import math, random\n","import torch.backends.cudnn as cudnn\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.autograd import Variable\n","from torch.utils.data import DataLoader\n","\n","\n","def adjust_learning_rate(optimizer, epoch):\n","    \"\"\"Sets the learning rate to the initial LR decayed by 10\"\"\"\n","    lr = lr * (0.1 ** (epoch // step))\n","    return lr\n","\n","def train(training_data_loader, optimizer, model, criterion, epoch):\n","\n","    lr = adjust_learning_rate(optimizer, epoch-1)\n","    \n","    for param_group in optimizer.param_groups:\n","        param_group[\"lr\"] = lr  \n","\n","    print(\"Epoch={}, lr={}\".format(epoch, optimizer.param_groups[0][\"lr\"]))\n","    model.train()\n","\n","    for iteration, batch in enumerate(training_data_loader, 1):\n","\n","        input, target = Variable(batch[0]), Variable(batch[1], requires_grad=False)\n","\n","        if cuda:\n","            input = input.cuda()\n","            target = target.cuda()\n","\n","        loss = criterion(model(input), target)\n","\n","        optimizer.zero_grad()\n","        \n","        loss.backward()\n","\n","        optimizer.step()\n","\n","        if iteration%100 == 0:\n","            print(\"===> Epoch[{}]({}/{}): Loss: {:.10f}\".format(epoch, iteration, len(training_data_loader), loss.data[0]))\n","\n","def save_checkpoint(model, epoch):\n","    model_folder = \"checkpoint/\"\n","    model_out_path = model_folder + \"model_epoch_{}.pth\".format(epoch)\n","    state = {\"epoch\": epoch ,\"model\": model}\n","    if not os.path.exists(model_folder):\n","        os.makedirs(model_folder)\n","\n","    torch.save(state, model_out_path)\n","\n","    print(\"Checkpoint saved to {}\".format(model_out_path))\n","\n","\n","def train_main(batchSize=16, nEpochs=500, lr=1e-4, step=200, resume='', seed=123, start_epoch=1, threads=1, momentum=0.9, weight_decay=1e-4):\n","    torch.manual_seed(seed)\n","    if cuda:\n","        torch.cuda.manual_seed(seed)\n","\n","    cudnn.benchmark = True\n","    device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n","\n","    print(\"===> Loading datasets\")\n","    train_set = DatasetFromHdf5(\"path_to_dataset.h5\")\n","    training_data_loader = DataLoader(dataset=train_set, num_workers=threads, batch_size=batchSize, shuffle=True)\n","\n","    print(\"===> Building model\")\n","    model = Net()\n","    criterion = nn.L1Loss(size_average=False)\n","\n","    print(\"===> Setting GPU\")\n","    if cuda:\n","        model = model.cuda()\n","        criterion = criterion.cuda()\n","\n","    # optionally resume from a checkpoint\n","    if resume:\n","        if os.path.isfile(resume):\n","            print(\"=> loading checkpoint '{}'\".format(resume))\n","            checkpoint = torch.load(resume)\n","            start_epoch = checkpoint[\"epoch\"] + 1\n","            model.load_state_dict(checkpoint[\"model\"].state_dict())\n","        else:\n","            print(\"=> no checkpoint found at '{}'\".format(resume))\n","\n","    print(\"===> Setting Optimizer\")\n","    optimizer = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=lr, weight_decay=weight_decay, betas = (0.9, 0.999), eps=1e-08)\n","\n","    print(\"===> Training\")\n","    for epoch in range(start_epoch, nEpochs + 1): \n","        train(training_data_loader, optimizer, model, criterion, epoch)\n","        save_checkpoint(model, epoch)\n"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"3MZg9B5H9dqP","executionInfo":{"status":"ok","timestamp":1620036649602,"user_tz":-330,"elapsed":4406,"user":{"displayName":"ASHISH KUMAR 4-Yr B.Tech. Comp. Sci. and Engg, 2018-2022","photoUrl":"","userId":"09157645467553063630"}}},"source":["import torch\n","import torch.backends.cudnn as cudnn\n","import numpy as np\n","import PIL.Image as pil_image\n","\n","\n","\n","from torch.autograd import Variable\n","\n","def test(weights_file, image_file, scale, save=False, debug=False, B=1, U=9, num_features=128):\n","    cudnn.benchmark = True\n","    device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n","\n","    model = EDSR()\n","    model.load_state_dict(torch.load(weights_file, map_location=device))\n","\n","    model.eval()\n","    model.to(device)\n","\n","    image = pil_image.open(image_file).convert('RGB')\n","    image_file = os.path.basename(image_file)\n","\n","    image_width = (image.width // scale) * scale\n","    image_height = (image.height // scale) * scale\n","\n","    hr = image.resize((image_width, image_height), resample=pil_image.BICUBIC)\n","    lr = hr.resize((hr.width // scale, hr.height // scale), resample=pil_image.BICUBIC)\n","    bicubic = lr.resize((lr.width * scale, lr.height * scale), resample=pil_image.BICUBIC)\n","\n","    hr = np.array(hr).astype(float)\n","    bicubic = np.array(bicubic).astype(float)\n","    im_l = np.array(lr).astype(float)\n","\n","    hr, _ = preprocess(hr, device)\n","    _, ycbcr = preprocess(bicubic, device)\n","\n","    im_input = im_l.astype(np.float32).transpose(2,0,1)\n","    im_input = im_input.reshape(1,im_input.shape[0],im_input.shape[1],im_input.shape[2])\n","    im_input = Variable(torch.from_numpy(im_input/255.).float()).to(device)\n","\n","    with torch.no_grad():\n","        preds = model(im_input)\n","\n","    preds = preds.cpu().data[0].numpy().astype(np.float32)\n","    preds = preds*255.\n","    preds = np.clip(preds, 0., 255.)\n","    preds = preds.transpose(1,2,0).astype(np.float32)\n","\n","    preds, _ = preprocess(preds, device)\n","\n","    psnr = calc_psnr(hr, preds)\n","    ssim = calc_ssim(hr, preds)\n","\n","    if debug:\n","        print(f'PSNR/SSIM: {psnr:.2f}/{ssim:.4f}')\n","\n","    preds = preds.mul(255.0).cpu().numpy().squeeze(0).squeeze(0)\n","\n","    output = np.array([preds, ycbcr[..., 1], ycbcr[..., 2]]).transpose([1, 2, 0])\n","    output = np.clip(convert_ycbcr_to_rgb(output), 0.0, 255.0).astype(np.uint8)\n","    output = pil_image.fromarray(output)\n","    if save:\n","        save_path = f'/content/drive/Shareddrives/BTP Meets/results/Set5/{scale}x/{image_file}'\n","        output.save(save_path.replace('.', '_edsr.'))\n","    return float(psnr), float(ssim)\n"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"_bwrF5pk9vIA","executionInfo":{"status":"ok","timestamp":1620036649604,"user_tz":-330,"elapsed":4404,"user":{"displayName":"ASHISH KUMAR 4-Yr B.Tech. Comp. Sci. and Engg, 2018-2022","photoUrl":"","userId":"09157645467553063630"}}},"source":["import os\n","\n","def do_test(psnr, ssim, BASE_DIR, save=False, debug=False):\n","    scales = [4]\n","\n","    for file in os.listdir(BASE_DIR):\n","        if file.endswith(\".png\"):\n","            image_file_path = os.path.join(BASE_DIR, file)\n","            if debug:\n","                print(file)\n","            for scale in scales:\n","                if debug:\n","                    print(f\"Scale: {scale}\")\n","                result = test(f'/content/drive/Shareddrives/BTP Meets/models/weights-edsr.pth', image_file_path, scale, save, debug)\n","                if scale not in psnr:\n","                    psnr[scale] = []\n","                if scale not in ssim:\n","                    ssim[scale] = []\n","                psnr[scale].append(result[0])\n","                ssim[scale].append(result[1])\n","            if debug:\n","                print()\n"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HcfXJaQk-BD8","executionInfo":{"status":"ok","timestamp":1620036722102,"user_tz":-330,"elapsed":76887,"user":{"displayName":"ASHISH KUMAR 4-Yr B.Tech. Comp. Sci. and Engg, 2018-2022","photoUrl":"","userId":"09157645467553063630"}},"outputId":"25ac9b04-7d09-4f65-c508-b1e523fba7ba"},"source":["psnr = {}\n","ssim = {}\n","do_test(psnr, ssim, '/content/drive/Shareddrives/BTP Meets/datasets/test/Set5/', True, True)"],"execution_count":8,"outputs":[{"output_type":"stream","text":["head.png\n","Scale: 4\n","PSNR/SSIM: 32.79/0.7941\n","\n","butterfly.png\n","Scale: 4\n","PSNR/SSIM: 27.93/0.9086\n","\n","bird.png\n","Scale: 4\n","PSNR/SSIM: 34.53/0.9374\n","\n","baby.png\n","Scale: 4\n","PSNR/SSIM: 33.32/0.8901\n","\n","woman.png\n","Scale: 4\n","PSNR/SSIM: 30.80/0.9179\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"3YadilgF-Ev2","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1619937476957,"user_tz":-330,"elapsed":1055,"user":{"displayName":"ASHISH KUMAR 4-Yr B.Tech. Comp. Sci. and Engg, 2018-2022","photoUrl":"","userId":"09157645467553063630"}},"outputId":"df6e7ba6-a084-4c31-dc2b-d8e4218dab17"},"source":["import statistics\n","\n","scales = [4]\n","for scale in scales:\n","    print(f'Avg PSNR/SSIM {scale}x: {statistics.mean(psnr[scale]):.2f}/{statistics.mean(ssim[scale]):.4f}')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Avg PSNR/SSIM 4x: 31.87/0.8896\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5WsOAWZ4vaOW","executionInfo":{"status":"ok","timestamp":1619932310129,"user_tz":-330,"elapsed":982803,"user":{"displayName":"ASHISH KUMAR 4-Yr B.Tech. Comp. Sci. and Engg, 2018-2022","photoUrl":"","userId":"09157645467553063630"}},"outputId":"7ebe1dd9-f1ab-4bd3-b0cd-a9813efaca86"},"source":["scales = [4]\n","\n","def calc_result(dataset):\n","    print()\n","    print(dataset)\n","    psnr = {}\n","    ssim = {}\n","    do_test(psnr, ssim, f'/content/drive/Shareddrives/BTP Meets/datasets/test/{dataset}/')\n","    for scale in scales:\n","        print(f'Avg PSNR/SSIM {scale}x: {statistics.mean(psnr[scale]):.2f}/{statistics.mean(ssim[scale]):.4f}')\n","\n","calc_result('Set14')\n","calc_result('BSDS100')\n","calc_result('Manga109')\n","calc_result('Urban100')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["\n","Set14\n","Avg PSNR/SSIM 4x: 28.10/0.7779\n","\n","BSDS100\n","Avg PSNR/SSIM 4x: 28.30/0.7606\n","\n","Manga109\n","Avg PSNR/SSIM 4x: 29.99/0.9057\n","\n","Urban100\n","Avg PSNR/SSIM 4x: 25.49/0.7691\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"zxKS9tTPvha3"},"source":[""],"execution_count":null,"outputs":[]}]}